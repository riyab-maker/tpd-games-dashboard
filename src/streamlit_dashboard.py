# âš ï¸ All data used in this dashboard must be preprocessed using preprocess_data.py before deployment.
# This dashboard only handles visualization of preprocessed data to stay within Render's 512MB memory limit.

import os
import json
import pandas as pd
import streamlit as st
from datetime import datetime
from typing import List, Tuple

# Check if processed data exists
DATA_DIR = "data"
REQUIRED_FILES = [
    "dashboard_data.csv",
    "summary_data.csv", 
    "score_distribution_data.csv",
    "time_series_data.csv",
    "repeatability_data.csv",
    "metadata.json"
]

def check_processed_data():
    """Check if all required processed data files exist"""
    missing_files = []
    for file in REQUIRED_FILES:
        file_path = os.path.join(DATA_DIR, file)
        if not os.path.exists(file_path):
            missing_files.append(file)
    
    if missing_files:
        st.error(f"ERROR: Missing processed data files: {', '.join(missing_files)}")
        st.error("WARNING: Please run 'python preprocess_data.py' locally to generate the required data files.")
        st.error("This dashboard requires preprocessed data to run efficiently on Render.")
        st.stop()
    
    return True

def load_processed_data():
    """Load all preprocessed data files"""
    try:
        # Load main data (use minimal dashboard_data.csv for filters and functionality)
        df_main = pd.DataFrame()
        if os.path.exists(os.path.join(DATA_DIR, "dashboard_data.csv")):
            df_main = pd.read_csv(os.path.join(DATA_DIR, "dashboard_data.csv"))
            df_main['server_time'] = pd.to_datetime(df_main['server_time'])
            df_main['date'] = pd.to_datetime(df_main['date'])
        elif os.path.exists(os.path.join(DATA_DIR, "processed_data.csv")):
            # Fallback to full data if available
            df_main = pd.read_csv(os.path.join(DATA_DIR, "processed_data.csv"))
            df_main['server_time'] = pd.to_datetime(df_main['server_time'])
            df_main['date'] = pd.to_datetime(df_main['date'])
        else:
            # Create a minimal dataframe for dashboard functionality
            df_main = pd.DataFrame({
                'idlink_va': [1],
                'idvisitor_converted': [1],
                'idvisit': [1],
                'server_time': [pd.Timestamp.now()],
                'idaction_name': [1],
                'custom_dimension_2': [1],
                'game_name': ['Sample Game'],
                'event': ['Started'],
                'date': [pd.Timestamp.now().date()]
            })
        
        # Load summary data
        summary_df = pd.read_csv(os.path.join(DATA_DIR, "summary_data.csv"))
        
        # Load score distribution data
        score_distribution_df = pd.DataFrame()
        if os.path.exists(os.path.join(DATA_DIR, "score_distribution_data.csv")):
            score_distribution_df = pd.read_csv(os.path.join(DATA_DIR, "score_distribution_data.csv"))
        
        # Load time series data
        time_series_df = pd.DataFrame()
        if os.path.exists(os.path.join(DATA_DIR, "time_series_data.csv")):
            time_series_df = pd.read_csv(os.path.join(DATA_DIR, "time_series_data.csv"))
        
        # Load repeatability data
        repeatability_df = pd.DataFrame()
        if os.path.exists(os.path.join(DATA_DIR, "repeatability_data.csv")):
            repeatability_df = pd.read_csv(os.path.join(DATA_DIR, "repeatability_data.csv"))
        
        # Load metadata
        metadata = {}
        if os.path.exists(os.path.join(DATA_DIR, "metadata.json")):
            with open(os.path.join(DATA_DIR, "metadata.json"), 'r') as f:
                metadata = json.load(f)
        
        return df_main, summary_df, score_distribution_df, time_series_df, repeatability_df, metadata
    
    except Exception as e:
        st.error(f"âŒ Error loading processed data: {str(e)}")
        st.error("Please ensure all data files are properly generated by running preprocess_data.py")
        st.stop()

def render_modern_dashboard(summary_df: pd.DataFrame, df_filtered: pd.DataFrame) -> None:
    """Render a modern, professional dashboard with multiple chart types"""
    import altair as alt
    
    # Add separate conversion funnels
    st.markdown("### ğŸ”„ Conversion Funnels")
    
    # Get data for each funnel from filtered data
    # Calculate unique users, visits, and instances from filtered data
    if 'Event' in df_filtered.columns:
        st.info(f"ğŸ” CONVERSION FUNNEL DEBUG: Using original summary data")
    else:
        st.info(f"ğŸ” CONVERSION FUNNEL DEBUG: df_filtered has {len(df_filtered)} events")
        st.info(f"ğŸ” Available events: {df_filtered['event'].unique()}")
        st.info(f"ğŸ” Started events: {len(df_filtered[df_filtered['event'] == 'Started'])}")
        st.info(f"ğŸ” Completed events: {len(df_filtered[df_filtered['event'] == 'Completed'])}")
    
    # Check if we're using summary data (original) or filtered data
    if 'Event' in df_filtered.columns:
        # Using summary data - get original totals
        started_users = df_filtered[df_filtered['Event'] == 'Started']['Users'].iloc[0]
        completed_users = df_filtered[df_filtered['Event'] == 'Completed']['Users'].iloc[0]
        started_visits = df_filtered[df_filtered['Event'] == 'Started']['Visits'].iloc[0]
        completed_visits = df_filtered[df_filtered['Event'] == 'Completed']['Visits'].iloc[0]
        started_instances = df_filtered[df_filtered['Event'] == 'Started']['Instances'].iloc[0]
        completed_instances = df_filtered[df_filtered['Event'] == 'Completed']['Instances'].iloc[0]
    else:
        # Using filtered data - calculate from filtered events
        try:
            started_users = df_filtered[df_filtered['event'] == 'Started']['idlink_va'].nunique()
            completed_users = df_filtered[df_filtered['event'] == 'Completed']['idlink_va'].nunique()
            started_visits = df_filtered[df_filtered['event'] == 'Started']['idvisit'].nunique()
            completed_visits = df_filtered[df_filtered['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(df_filtered[df_filtered['event'] == 'Started'])
            completed_instances = len(df_filtered[df_filtered['event'] == 'Completed'])
        except KeyError as e:
            st.error(f"âŒ Column error: {e}")
            st.error(f"Available columns: {df_filtered.columns.tolist()}")
            st.stop()
    
    # Debug: Show data info
    if 'Event' in df_filtered.columns:
        st.info(f"ğŸ”„ Conversion Funnel - Using original summary data")
    else:
        st.info(f"ğŸ”„ Conversion Funnel - Filtered data: {len(df_filtered)} events, {len(df_filtered['game_name'].unique())} games")
    st.info(f"ğŸ“Š Numbers: Started Users={started_users}, Completed Users={completed_users}, Started Visits={started_visits}, Completed Visits={completed_visits}")
    
    # Create three separate funnels
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸ‘¥ Users Funnel")
        users_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_users, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_users, 'Order': 1}
        ])
        
        users_chart = alt.Chart(users_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#4A90E2'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        users_labels = alt.Chart(users_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        users_funnel = alt.layer(users_chart, users_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(users_funnel, use_container_width=True)
    
    with col2:
        st.markdown("#### ğŸ”„ Visits Funnel")
        visits_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_visits, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_visits, 'Order': 1}
        ])
        
        visits_chart = alt.Chart(visits_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#7ED321'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        visits_labels = alt.Chart(visits_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        visits_funnel = alt.layer(visits_chart, visits_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(visits_funnel, use_container_width=True)
    
    with col3:
        st.markdown("#### âš¡ Instances Funnel")
        instances_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_instances, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_instances, 'Order': 1}
        ])
        
        instances_chart = alt.Chart(instances_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#F5A623'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        instances_labels = alt.Chart(instances_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        instances_funnel = alt.layer(instances_chart, instances_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(instances_funnel, use_container_width=True)
    
    # Add conversion analysis
    st.markdown("### ğŸ“Š Conversion Analysis")
    
    analysis_col1, analysis_col2, analysis_col3 = st.columns(3)
    
    with analysis_col1:
        user_conversion = (completed_users / started_users * 100) if started_users > 0 else 0
        st.metric(
            label="ğŸ‘¥ User Conversion",
            value=f"{user_conversion:.1f}%",
            help=f"{completed_users:,} out of {started_users:,} users completed"
        )
    
    with analysis_col2:
        started_visits = summary_df[summary_df['Event'] == 'Started']['Visits'].iloc[0]
        completed_visits = summary_df[summary_df['Event'] == 'Completed']['Visits'].iloc[0]
        visit_conversion = (completed_visits / started_visits * 100) if started_visits > 0 else 0
        st.metric(
            label="ğŸ”„ Visit Conversion",
            value=f"{visit_conversion:.1f}%",
            help=f"{completed_visits:,} out of {started_visits:,} visits completed"
        )
    
    with analysis_col3:
        instance_conversion = (completed_instances / started_instances * 100) if started_instances > 0 else 0
        st.metric(
            label="âš¡ Instance Conversion",
            value=f"{instance_conversion:.1f}%",
            help=f"{completed_instances:,} out of {started_instances:,} instances completed"
        )

def render_score_distribution_chart(score_distribution_df: pd.DataFrame) -> None:
    """Render score distribution chart"""
    import altair as alt
    
    # Debug message
    st.info("ğŸ”§ Score Distribution Function Called - Version 1.3")
    
    if score_distribution_df.empty:
        st.warning("No score distribution data available.")
        return
    
    # Get unique games for filter
    unique_games = sorted(score_distribution_df['game_name'].unique())
    
    # Add game filter
    st.markdown("**ğŸ® Game Filter:**")
    st.info(f"Available games: {len(unique_games)} games")
    selected_games = st.multiselect(
        "Select Games for Score Distribution:",
        options=unique_games,
        default=[],  # Empty by default - shows all games
        help="Select one or more games to show score distribution. Leave empty to show all games."
    )
    
    # Filter data based on selected games
    if selected_games:
        filtered_df = score_distribution_df[score_distribution_df['game_name'].isin(selected_games)]
        # Show filter status
        if len(selected_games) == len(unique_games):
            st.info("ğŸ® Showing data for: **All Games**")
        else:
            st.info(f"ğŸ® Showing data for: {', '.join(selected_games)}")
    else:
        # Empty selection means all games
        filtered_df = score_distribution_df
        st.info("ğŸ® Showing data for: **All Games**")
    
    if filtered_df.empty:
        st.warning("No data available for the selected games.")
        return
    
    # Create the score distribution chart
    st.markdown("### ğŸ“Š Score Distribution")
    st.markdown("This chart shows how many users achieved each total score for the selected games.")
    
    # Add combined score distribution (all games together)
    st.markdown("#### ğŸ¯ Score Distribution")
    
    # Create combined data by summing user counts across all games for each score
    combined_df = filtered_df.groupby('total_score')['user_count'].sum().reset_index()
    combined_df.columns = ['total_score', 'total_users']
    
    if not combined_df.empty:
        # Create combined bar chart
        combined_bars = alt.Chart(combined_df).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#FF6B6B'
        ).encode(
            x=alt.X('total_score:O', 
                    title='Total Score', 
                    axis=alt.Axis(
                        labelAngle=0,
                        labelFontSize=14,
                        titleFontSize=16,
                        labelLimit=100
                    )),
            y=alt.Y('total_users:Q', 
                    title='Total Number of Users', 
                    axis=alt.Axis(format='~s')),
            tooltip=['total_score:O', 'total_users:Q']
        ).properties(
            width=900,
            height=400,
            title='Score Distribution'
        )
        
        # Add data labels for combined chart
        combined_labels = alt.Chart(combined_df).mark_text(
            align='center',
            baseline='bottom',
            color='#2E8B57',
            fontSize=12,
            fontWeight='bold',
            dy=-5
        ).encode(
            x=alt.X('total_score:O'),
            y=alt.Y('total_users:Q'),
            text=alt.Text('total_users:Q', format='.0f')
        )
        
        # Combine bars and labels for combined chart
        combined_chart = (combined_bars + combined_labels).configure_axis(
            labelFontSize=16,
            titleFontSize=18,
            grid=True
        ).configure_title(
            fontSize=24,
            fontWeight='bold'
        )
        
        st.altair_chart(combined_chart, use_container_width=True)
    
    # Add summary statistics after the chart
    st.markdown("#### ğŸ“ˆ Summary Statistics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_users = filtered_df['user_count'].sum()
        st.metric(
            label="ğŸ‘¥ Total Users",
            value=f"{total_users:,}",
            help="Total number of users across all games and scores"
        )
    
    with col2:
        avg_score = (filtered_df['total_score'] * filtered_df['user_count']).sum() / filtered_df['user_count'].sum()
        st.metric(
            label="ğŸ¯ Average Score",
            value=f"{avg_score:.1f}",
            help="Weighted average score across all users"
        )
    
    with col3:
        max_score = filtered_df['total_score'].max()
        st.metric(
            label="ğŸ† Highest Score",
            value=f"{max_score}",
            help="Maximum total score achieved"
        )
    
    with col4:
        unique_games_count = filtered_df['game_name'].nunique()
        st.metric(
            label="ğŸ® Games Analyzed",
            value=f"{unique_games_count}",
            help="Number of games included in the analysis"
        )

def render_repeatability_analysis(repeatability_df: pd.DataFrame) -> None:
    """Render game repeatability analysis based on SQL query logic:
    
    SQL Query Logic:
    1. JOIN hybrid_games, hybrid_games_links, hybrid_game_completions, hybrid_profiles, hybrid_users
    2. Group by hybrid_profile_id
    3. Count distinct non-null values of game_name for each hybrid_profile_id
    4. Group by the count of distinct non-null game_name
    5. Calculate CountDistinct_hybrid_profile_id for each distinct count value
    
    Visualization:
    X-axis â†’ number of distinct games played (repeat count)
    Y-axis â†’ number of unique users (hybrid_profile_id) corresponding to each repeat count
    """
    import altair as alt
    
    if repeatability_df.empty:
        st.warning("No repeatability data available.")
        return
    
    st.markdown("### ğŸ® Game Repeatability Analysis")
    st.info("ğŸ“Š Analysis based on SQL query: JOIN hybrid_games â†’ hybrid_games_links â†’ hybrid_game_completions â†’ hybrid_profiles â†’ hybrid_users")
    
    # Create the repeatability chart with explicit axis configuration
    chart = alt.Chart(repeatability_df).mark_bar(
        cornerRadius=6,
        stroke='white',
        strokeWidth=2,
        color='#50C878'
    ).encode(
        x=alt.X('games_played:O', 
                title='No of games played', 
                axis=alt.Axis(labelAngle=0, titleFontSize=24, labelFontSize=22)),
        y=alt.Y('user_count:Q', 
                title='Number of Users', 
                axis=alt.Axis(format='~s', titleFontSize=24, labelFontSize=22)),
        tooltip=['games_played:O', 'user_count:Q']
    ).properties(
        width=800,
        height=400,
        title='User Distribution by Number of Distinct Games Completed'
    )
    
    # Add text labels
    text = alt.Chart(repeatability_df).mark_text(
        align='center',
        baseline='bottom',
        color='#2E8B57',
        fontSize=20,
        fontWeight='bold',
        dy=-10
    ).encode(
        x=alt.X('games_played:O'),
        y=alt.Y('user_count:Q'),
        text=alt.Text('user_count:Q', format='.0f')
    )
    
    # Combine chart and text
    repeatability_chart = (chart + text).configure_axis(
        grid=True
    ).configure_title(
        fontSize=28,
        fontWeight='bold'
    )
    
    st.altair_chart(repeatability_chart, use_container_width=True)
    
    # Add summary statistics based on SQL query logic
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_users = repeatability_df['user_count'].sum()
        st.metric(
            label="ğŸ‘¥ Total Unique Users",
            value=f"{total_users:,}",
            help="Total number of unique hybrid_profile_id who completed at least one distinct game"
        )
    
    with col2:
        # Calculate weighted average of distinct games per user
        weighted_sum = (repeatability_df['games_played'] * repeatability_df['user_count']).sum()
        total_users = repeatability_df['user_count'].sum()
        avg_distinct_games_per_user = weighted_sum / total_users if total_users > 0 else 0
        st.metric(
            label="ğŸ¯ Avg Distinct Games per User",
            value=f"{avg_distinct_games_per_user:.1f}",
            help="Average number of distinct games completed per hybrid_profile_id"
        )
    
    with col3:
        max_distinct_games = repeatability_df['games_played'].max()
        st.metric(
            label="ğŸ† Max Distinct Games",
            value=f"{max_distinct_games}",
            help="Maximum number of distinct games completed by a single hybrid_profile_id"
        )

def recalculate_time_series_for_games(df_main: pd.DataFrame, time_period: str) -> pd.DataFrame:
    """Recalculate time series data for selected games"""
    if df_main.empty:
        return pd.DataFrame()
    
    # Convert date to datetime (use the correct date column)
    df_main['datetime'] = pd.to_datetime(df_main['date'])
    
    # Filter to July 2nd, 2025 onwards
    july_2_2025 = pd.to_datetime('2025-07-02')
    df_main = df_main[df_main['datetime'] >= july_2_2025]
    
    time_series_data = []
    
    if time_period == "Day":
        # Day-level data (last 2 weeks from available data)
        cutoff_date = df_main['datetime'].max() - pd.Timedelta(days=14)
        df_filtered = df_main[df_main['datetime'] >= cutoff_date].copy()
        df_filtered['time_group'] = df_filtered['datetime'].dt.date
        
        for time_group in df_filtered['time_group'].unique():
            group_data = df_filtered[df_filtered['time_group'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': str(time_group),
                'period_type': 'Day',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "Week":
        # Week-level data (all available data grouped by weeks)
        # Use the earliest date in the data as the reference point
        start_date = df_main['datetime'].min()
        df_filtered = df_main.copy()
        df_filtered['days_since_start'] = (df_filtered['datetime'] - start_date).dt.days
        df_filtered['week_number'] = (df_filtered['days_since_start'] // 7) + 1
        df_filtered['time_group_week'] = 'Week ' + df_filtered['week_number'].astype(str)
        
        for time_group in df_filtered['time_group_week'].unique():
            group_data = df_filtered[df_filtered['time_group_week'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'Week',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "Month":
        # Month-level data (all available data grouped by months)
        df_filtered = df_main.copy()
        df_filtered['time_group_month'] = df_filtered['datetime'].dt.strftime('%B %Y')
        
        for time_group in df_filtered['time_group_month'].unique():
            group_data = df_filtered[df_filtered['time_group_month'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'Month',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "All time":
        # All time data (all available data grouped by months)
        # Use the same logic as Month but with different period_type
        df_filtered = df_main.copy()
        df_filtered['time_group_month'] = df_filtered['datetime'].dt.strftime('%B %Y')
        
        for time_group in df_filtered['time_group_month'].unique():
            group_data = df_filtered[df_filtered['time_group_month'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'All time',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    return pd.DataFrame(time_series_data)

def render_time_series_analysis(time_series_df: pd.DataFrame, df_main: pd.DataFrame) -> None:
    """Render time series analysis"""
    import altair as alt
    
    if time_series_df.empty:
        st.warning("No time series data available.")
        return
    
    st.markdown("### ğŸ“ˆ Time-Series Analysis")
    st.info("ğŸ“… Time series data shows activity from July 2nd, 2025 onwards")
    
    # Create columns for filters
    ts_filter_col1, ts_filter_col2, ts_filter_col3 = st.columns(3)
    
    with ts_filter_col1:
        # Time period filter
        time_period = st.selectbox(
            "Select Time Period:",
            options=["Month", "Week", "Day"],
            help="Choose the time aggregation for the time-series graphs"
        )
    
    with ts_filter_col2:
        # Game filter for time series
        unique_games_ts = sorted(df_main['game_name'].unique())
        selected_games_ts = st.multiselect(
            "Select Games:",
            options=unique_games_ts,
            default=[],  # Empty by default - shows all games
            help="Select games to include in time series analysis. Leave empty to show all games."
        )
    
    with ts_filter_col3:
        # Show data info
        st.info(f"ğŸ“Š Showing {len(time_series_df)} time periods")
    
    # Use only preprocessed data (like all other graphs)
    if time_series_df.empty:
        st.warning("No time series data available.")
        return
    
    # Filter by selected time period
    filtered_ts_df = time_series_df[time_series_df['period_type'] == time_period].copy()
    
    # Apply July filter for Month view
    if time_period == "Month":
        july_onwards = ['July 2025', 'August 2025', 'September 2025', 'October 2025']
        filtered_ts_df = filtered_ts_df[filtered_ts_df['time_period'].isin(july_onwards)]
    
    # Apply game filtering if specific games are selected
    if selected_games_ts:
        # Filter by selected games
        filtered_ts_df = filtered_ts_df[filtered_ts_df['game_name'].isin(selected_games_ts)]
        if len(selected_games_ts) == len(unique_games_ts):
            st.info("ğŸ® Filtering time series for: **All Games**")
        else:
            st.info(f"ğŸ® Filtering time series for: {', '.join(selected_games_ts)}")
    else:
        # Empty selection means all games
        st.info("ğŸ® Filtering time series for: **All Games**")
    
    # Aggregate data by time period to prevent overlapping points
    # Group by time_period and sum the metrics
    aggregated_df = filtered_ts_df.groupby('time_period').agg({
        'started_users': 'sum',
        'completed_users': 'sum',
        'started_visits': 'sum',
        'completed_visits': 'sum',
        'started_instances': 'sum',
        'completed_instances': 'sum'
    }).reset_index()
    
    # Show data info
    st.info(f"ğŸ“Š Showing {len(aggregated_df)} time periods for {time_period} view")
    
    if filtered_ts_df.empty:
        st.warning("No data available for the selected time period.")
        return
    
    # Sort the aggregated dataframe based on time period
    if time_period == "Month":
        # Convert month names to datetime for proper sorting
        try:
            aggregated_df['sort_date'] = pd.to_datetime(aggregated_df['time_period'])
            aggregated_df = aggregated_df.sort_values('sort_date').drop('sort_date', axis=1)
            # Create ordered list for Altair
            time_order = aggregated_df['time_period'].tolist()
        except Exception as e:
            # If datetime parsing fails, use original order
            st.warning(f"Could not parse dates for sorting: {e}")
            time_order = aggregated_df['time_period'].tolist()
    elif time_period == "Week":
        # Extract week number for sorting
        aggregated_df['week_num'] = aggregated_df['time_period'].str.extract(r'(\d+)').astype(int)
        aggregated_df = aggregated_df.sort_values('week_num').drop('week_num', axis=1)
        # Create ordered list for Altair
        time_order = aggregated_df['time_period'].tolist()
    elif time_period == "Day":
        # Sort by date
        try:
            aggregated_df['sort_date'] = pd.to_datetime(aggregated_df['time_period'])
            aggregated_df = aggregated_df.sort_values('sort_date').drop('sort_date', axis=1)
            # Create ordered list for Altair
            time_order = aggregated_df['time_period'].astype(str).tolist()
        except Exception as e:
            # If datetime parsing fails, use original order
            st.warning(f"Could not parse dates for sorting: {e}")
            time_order = aggregated_df['time_period'].astype(str).tolist()
    else:
        time_order = None
    
    # Create separate sections for each metric with tabs for different time periods
    def create_metric_chart(data, metric_name, metric_key, color_scheme):
        """Create chart for a specific metric"""
        chart_data = []
        for _, row in data.iterrows():
            chart_data.extend([
                {'Time': str(row['time_period']), 'Event': 'Started', 'Count': row[f'started_{metric_key}']},
                {'Time': str(row['time_period']), 'Event': 'Completed', 'Count': row[f'completed_{metric_key}']}
            ])
        chart_df = pd.DataFrame(chart_data)
        
        # Line chart for time periods
        lines = alt.Chart(chart_df).mark_line(
            strokeWidth=3,
            point=alt.OverlayMarkDef(
                filled=True,
                size=60,
                stroke='white',
                strokeWidth=1.5
            )
        ).encode(
            x=alt.X('Time:N', title='Time Period', 
                   sort=time_order if time_order else None,
                   axis=alt.Axis(
                       labelAngle=0,
                       labelFontSize=12,
                       labelLimit=150,
                       titleFontSize=14
                   )),
            y=alt.Y('Count:Q', title=f'Number of {metric_name}', axis=alt.Axis(format='~s')),
            color=alt.Color('Event:N', 
                          scale=alt.Scale(domain=['Started', 'Completed'], 
                                        range=color_scheme),
                          legend=alt.Legend(title="Event Type")),
            tooltip=['Time:N', 'Event:N', 'Count:Q']
        ).properties(
            width=900,
            height=400,
            title=f'{metric_name}: Started vs Completed'
        )
        
        # Add data labels only for every other point to reduce clutter
        started_data = chart_df[chart_df['Event'] == 'Started']
        completed_data = chart_df[chart_df['Event'] == 'Completed']
        
        # Show labels only for every other point to reduce clutter
        started_labels = alt.Chart(started_data[::2]).mark_text(
            align='center',
            baseline='bottom',
            color=color_scheme[0],
            fontSize=11,
            fontWeight='bold',
            dy=-12
        ).encode(
            x=alt.X('Time:N', sort=time_order if time_order else None),
            y=alt.Y('Count:Q'),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        completed_labels = alt.Chart(completed_data[::2]).mark_text(
            align='center',
            baseline='top',
            color=color_scheme[1],
            fontSize=11,
            fontWeight='bold',
            dy=12
        ).encode(
            x=alt.X('Time:N', sort=time_order if time_order else None),
            y=alt.Y('Count:Q'),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        return (lines + started_labels + completed_labels).configure_axis(
            labelFontSize=18,
            titleFontSize=20,
            grid=True
        ).configure_title(
            fontSize=24,
            fontWeight='bold'
        )
    
    # Users Section
    st.markdown("### ğŸ‘¥ Users Analysis")
    users_chart = create_metric_chart(aggregated_df, "Users", "users", ['#FF6B6B', '#4ECDC4'])
    st.altair_chart(users_chart, use_container_width=True)
    
    # Visits Section
    st.markdown("### ğŸ”„ Visits Analysis")
    visits_chart = create_metric_chart(aggregated_df, "Visits", "visits", ['#FF6B6B', '#4ECDC4'])
    st.altair_chart(visits_chart, use_container_width=True)
    
    # Instances Section
    st.markdown("### âš¡ Instances Analysis")
    instances_chart = create_metric_chart(aggregated_df, "Instances", "instances", ['#FF6B6B', '#4ECDC4'])
    st.altair_chart(instances_chart, use_container_width=True)

def main() -> None:
    st.set_page_config(page_title="Matomo Events Dashboard", layout="wide")
    st.title("Matomo Events Dashboard")
    st.caption("All data (server_time adjusted by +5h30m) | Version: 2.2 - COMPLETE REWRITE")
    
    # Force deployment check
    st.success("ğŸš€ CONVERSION FUNNEL NOW FILTERS BY GAME! Test by selecting different games.")
    st.warning("âš ï¸ If you still see old numbers, hard refresh your browser (Ctrl+F5)")
    
    # Check if processed data exists
    check_processed_data()
    
    with st.spinner("Loading preprocessed data..."):
        df_main, summary_df, score_distribution_df, time_series_df, repeatability_df, metadata = load_processed_data()
    
    if df_main.empty:
        st.warning("No data available.")
        return
    
    # Show data info
    if metadata:
        st.info(f"ğŸ“Š Data last updated: {metadata.get('preprocessing_date', 'Unknown')} | Records: {metadata.get('main_data_records', 'Unknown')}")
    
    # Add filters
    st.markdown("### ğŸ® Filters")
    
    # Create two columns for filters
    filter_col1, filter_col2 = st.columns(2)
    
    with filter_col1:
        # Game Name filter
        unique_games = sorted(df_main['game_name'].unique())
        selected_games = st.multiselect(
            "Select Game Names to filter by:",
            options=unique_games,
            default=[],  # Empty by default - shows all games
            help="Select one or more games to filter the dashboard data. Leave empty to show all games."
        )
    
    with filter_col2:
        # Date filter
        # Set minimum date to July 2nd, 2025
        min_date = pd.to_datetime('2025-07-02').date()
        max_date = df_main['date'].max()
        
        # Create date range picker
        date_range = st.date_input(
            "Select Date Range:",
            value=(min_date, max_date),
            min_value=min_date,
            max_value=max_date,
            help="Select a date range to filter the data. The server_time is already adjusted by +5h30m. Data is available from July 2nd, 2025 onwards."
        )
    
    # Apply filters
    df_filtered = df_main.copy()
    
    # Apply game filter
    if selected_games:
        df_filtered = df_filtered[df_filtered['game_name'].isin(selected_games)]
        st.info(f"ğŸ® GAME FILTER APPLIED: {len(selected_games)} games selected, {len(df_filtered)} events remaining")
    else:
        st.info(f"ğŸ® NO GAME FILTER: Showing all {len(df_filtered)} events from {df_filtered['game_name'].nunique()} games")
    # If no games selected, show all games (no filtering needed)
    
    # Apply date filter
    if len(date_range) == 2:  # Both start and end date selected
        start_date, end_date = date_range
        # Convert date column to datetime for proper comparison
        df_filtered['date'] = pd.to_datetime(df_filtered['date']).dt.date
        df_filtered = df_filtered[
            (df_filtered['date'] >= start_date) & 
            (df_filtered['date'] <= end_date)
        ]
    elif len(date_range) == 1:  # Only one date selected
        # Convert date column to datetime for proper comparison
        df_filtered['date'] = pd.to_datetime(df_filtered['date']).dt.date
        df_filtered = df_filtered[df_filtered['date'] == date_range[0]]
    
    if df_filtered.empty:
        st.warning("No data available for the selected filters.")
        return
    
    # Show filter summary
    if len(date_range) == 2:
        date_summary = f"from {date_range[0]} to {date_range[1]}"
    elif len(date_range) == 1:
        date_summary = f"on {date_range[0]}"
    else:
        date_summary = "for all dates"
    
    # Show filter summary
    if not selected_games or len(selected_games) == len(unique_games):
        game_summary = "**All Games**"
        game_count = len(unique_games)
    else:
        game_summary = f"{', '.join(selected_games)}"
        game_count = len(selected_games)
    
    st.info(f"ğŸ“Š Showing data for {game_count} selected game(s): {game_summary} | Date range: {date_summary}")

    # Use filtered data for conversion funnel to respect game filter
    st.info(f"ğŸ”„ PASSING TO CONVERSION FUNNEL: {len(df_filtered)} events, games: {sorted(df_filtered['game_name'].unique())}")
    
    # If no games selected, use original summary data; if games selected, use filtered data
    if not selected_games or len(selected_games) == len(unique_games):
        render_modern_dashboard(summary_df, summary_df)  # Use original totals
    else:
        render_modern_dashboard(summary_df, df_filtered)  # Use filtered data
    
    # Add Score Distribution Analysis
    st.markdown("---")
    st.markdown("## ğŸ¯ Score Distribution Analysis")
    
    if not score_distribution_df.empty:
        render_score_distribution_chart(score_distribution_df)
    else:
        st.warning("No score distribution data available.")
    
    # Add Repeatability Analysis
    st.markdown("---")
    st.markdown("## ğŸ® Game Repeatability Analysis")
    
    if not repeatability_df.empty:
        render_repeatability_analysis(repeatability_df)
    else:
        st.warning("No repeatability data available.")
    
    # Add Time Series Analysis
    st.markdown("---")
    st.markdown("## ğŸ“ˆ Time-Series Analysis")
    
    if not time_series_df.empty:
        render_time_series_analysis(time_series_df, df_main)
    else:
        st.warning("No time series data available.")


if __name__ == "__main__":
    main()