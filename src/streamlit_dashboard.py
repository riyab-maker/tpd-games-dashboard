# ‚ö†Ô∏è All data used in this dashboard must be preprocessed using master_processor.py before deployment.
# This dashboard only handles visualization of preprocessed data to stay within Render's 512MB memory limit.

import os
import json
import pandas as pd
import streamlit as st
from datetime import datetime
from typing import List, Tuple

# Use preprocess_data.py directly instead of processed CSV files
DATA_DIR = "data"
REQUIRED_FILES = [
    "summary_data.csv",
    "time_series_data.csv",
    "repeatability_data.csv",
    "score_distribution_data.csv",
    "game_conversion_numbers.csv",
    "poll_responses_data.csv"
]

def check_processed_data():
    """Check if all required processed data files exist"""
    # Check if DATA_DIR exists
    if not os.path.exists(DATA_DIR):
        st.error(f"ERROR: Data directory does not exist: {DATA_DIR}")
        st.error("Please ensure data folder is uploaded to GitHub.")
        st.stop()
    
    missing_files = []
    for file in REQUIRED_FILES:
        file_path = os.path.join(DATA_DIR, file)
        if not os.path.exists(file_path):
            missing_files.append(file)
    
    if missing_files:
        st.error(f"Missing processed data files: {', '.join(missing_files)}")
        st.error("Please ensure all data files are uploaded to GitHub before deployment.")
        st.error("This dashboard only works with preprocessed data files.")
        st.stop()
    
    return True

def load_processed_data():
    """Load all data files from data/ directory"""
    try:
        # Load game-specific conversion numbers (final numbers for individual games)
        game_conversion_df = pd.read_csv(os.path.join(DATA_DIR, "game_conversion_numbers.csv"))
        
        # Load summary data for conversion funnels
        summary_df = pd.read_csv(os.path.join(DATA_DIR, "summary_data.csv"))
        
        # Load time series data
        time_series_df = pd.read_csv(os.path.join(DATA_DIR, "time_series_data.csv"))
        
        # Load repeatability data
        repeatability_df = pd.read_csv(os.path.join(DATA_DIR, "repeatability_data.csv"))
        
        # Load score distribution data
        score_distribution_df = pd.read_csv(os.path.join(DATA_DIR, "score_distribution_data.csv"))
        
        # Load poll responses data
        poll_responses_df = pd.read_csv(os.path.join(DATA_DIR, "poll_responses_data.csv"))
        
        # Create metadata
        metadata = {
            'last_updated': datetime.now().isoformat(),
            'data_source': 'data',
            'version': '2.0'
        }
        
        return (summary_df, game_conversion_df, time_series_df, 
                repeatability_df, score_distribution_df, poll_responses_df, metadata)
    
    except Exception as e:
        st.error(f"‚ùå Error loading processed data: {str(e)}")
        st.error("Please ensure all data files are properly generated by running preprocess_data.py")
        st.stop()

def render_modern_dashboard(conversion_df: pd.DataFrame, df_filtered: pd.DataFrame) -> None:
    """Render a modern, professional dashboard with multiple chart types"""
    import altair as alt
    
    # Add separate conversion funnels
    st.markdown("### üîÑ Conversion Funnels")
    
    # Display date range for conversion funnel
    st.caption(f"üìÖ Data range: July 2nd, 2025 onwards (Total: {conversion_df[conversion_df['Event'] == 'Started']['Users'].iloc[0]:,} users started, {conversion_df[conversion_df['Event'] == 'Completed']['Users'].iloc[0]:,} users completed)")

    # Get data for each funnel from conversion data
    if 'Event' in conversion_df.columns:
        # Summary data format (total data)
        started_users = conversion_df[conversion_df['Event'] == 'Started']['Users'].iloc[0]
        completed_users = conversion_df[conversion_df['Event'] == 'Completed']['Users'].iloc[0]
        started_visits = conversion_df[conversion_df['Event'] == 'Started']['Visits'].iloc[0]
        completed_visits = conversion_df[conversion_df['Event'] == 'Completed']['Visits'].iloc[0]
        started_instances = conversion_df[conversion_df['Event'] == 'Started']['Instances'].iloc[0]
        completed_instances = conversion_df[conversion_df['Event'] == 'Completed']['Instances'].iloc[0]
    else:
        # Filtered data format - calculate from raw data
        started_users = conversion_df[conversion_df['event'] == 'Started']['idvisitor_converted'].nunique()
        completed_users = conversion_df[conversion_df['event'] == 'Completed']['idvisitor_converted'].nunique()
        started_visits = conversion_df[conversion_df['event'] == 'Started']['idvisit'].nunique()
        completed_visits = conversion_df[conversion_df['event'] == 'Completed']['idvisit'].nunique()
        started_instances = len(conversion_df[conversion_df['event'] == 'Started'])
        completed_instances = len(conversion_df[conversion_df['event'] == 'Completed'])
    
    
    # Create three separate funnels
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### üë• Users Funnel")
        users_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_users, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_users, 'Order': 1}
        ])
        
        users_chart = alt.Chart(users_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#4A90E2'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        users_labels = alt.Chart(users_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        users_funnel = alt.layer(users_chart, users_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(users_funnel, use_container_width=True)
    
    with col2:
        st.markdown("#### üîÑ Visits Funnel")
        visits_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_visits, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_visits, 'Order': 1}
        ])
        
        visits_chart = alt.Chart(visits_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#7ED321'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        visits_labels = alt.Chart(visits_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        visits_funnel = alt.layer(visits_chart, visits_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(visits_funnel, use_container_width=True)
    
    with col3:
        st.markdown("#### ‚ö° Instances Funnel")
        instances_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_instances, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_instances, 'Order': 1}
        ])
        
        instances_chart = alt.Chart(instances_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#F5A623'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        instances_labels = alt.Chart(instances_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        instances_funnel = alt.layer(instances_chart, instances_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(instances_funnel, use_container_width=True)
    
    # Add conversion analysis
    st.markdown("### üìä Conversion Analysis")
    
    analysis_col1, analysis_col2, analysis_col3 = st.columns(3)
    
    with analysis_col1:
        user_conversion = (completed_users / started_users * 100) if started_users > 0 else 0
        st.metric(
            label="üë• User Conversion",
            value=f"{user_conversion:.1f}%",
            help=f"{completed_users:,} out of {started_users:,} users completed"
        )
    
    with analysis_col2:
        visit_conversion = (completed_visits / started_visits * 100) if started_visits > 0 else 0
        st.metric(
            label="üîÑ Visit Conversion",
            value=f"{visit_conversion:.1f}%",
            help=f"{completed_visits:,} out of {started_visits:,} visits completed"
        )
    
    with analysis_col3:
        instance_conversion = (completed_instances / started_instances * 100) if started_instances > 0 else 0
        st.metric(
            label="‚ö° Instance Conversion",
            value=f"{instance_conversion:.1f}%",
            help=f"{completed_instances:,} out of {started_instances:,} instances completed"
        )

def render_score_distribution_chart(score_distribution_df: pd.DataFrame) -> None:
    """Render score distribution chart"""
    import altair as alt
    
    
    if score_distribution_df.empty:
        st.warning("No score distribution data available.")
        return
    
    # Get unique games for filter
    unique_games = sorted(score_distribution_df['game_name'].unique())
    
    # Add game filter
    st.markdown("**üéÆ Game Filter:**")
    selected_games = st.multiselect(
        "Select Games for Score Distribution:",
        options=unique_games,
        default=[unique_games[0]] if unique_games else [],  # Show first game by default
        help="Select one or more games to show score distribution. First game is selected by default."
    )
    
    # Filter data based on selected games
    if selected_games:
        filtered_df = score_distribution_df[score_distribution_df['game_name'].isin(selected_games)]
    else:
        # If no games selected, show first game
        filtered_df = score_distribution_df[score_distribution_df['game_name'] == unique_games[0]] if unique_games else score_distribution_df
    
    if filtered_df.empty:
        st.warning("No data available for the selected games.")
        return
    
    # Create the score distribution chart
    st.markdown("### üìä Score Distribution")
    if len(selected_games) == 1:
        st.markdown(f"This chart shows how many users achieved each total score for **{selected_games[0]}**.")
    else:
        st.markdown(f"This chart shows how many users achieved each total score for the selected games ({len(selected_games)} games).")
    
    # Add score distribution chart
    st.markdown("#### üéØ Score Distribution")
    
    # Create combined data by summing user counts across all games for each score
    combined_df = filtered_df.groupby('total_score')['user_count'].sum().reset_index()
    combined_df.columns = ['total_score', 'total_users']
    
    if not combined_df.empty:
        # Create combined bar chart
        combined_bars = alt.Chart(combined_df).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#FF6B6B'
        ).encode(
            x=alt.X('total_score:O', 
                    title='Total Score', 
                    axis=alt.Axis(
                        labelAngle=0,
                        labelFontSize=14,
                        titleFontSize=16,
                        labelLimit=100
                    )),
            y=alt.Y('total_users:Q', 
                    title='Total Number of Users', 
                    axis=alt.Axis(format='~s')),
            tooltip=['total_score:O', 'total_users:Q']
        ).properties(
            width=900,
            height=400,
            title='Score Distribution'
        )
        
        # Add data labels for combined chart
        combined_labels = alt.Chart(combined_df).mark_text(
            align='center',
            baseline='bottom',
            color='#2E8B57',
            fontSize=12,
            fontWeight='bold',
            dy=-5
        ).encode(
            x=alt.X('total_score:O'),
            y=alt.Y('total_users:Q'),
            text=alt.Text('total_users:Q', format='.0f')
        )
        
        # Combine bars and labels for combined chart
        combined_chart = (combined_bars + combined_labels).configure_axis(
            labelFontSize=16,
            titleFontSize=18,
            grid=True
        ).configure_title(
            fontSize=24,
            fontWeight='bold'
        )
        
        st.altair_chart(combined_chart, use_container_width=True)
    
    # Add summary statistics after the chart
    st.markdown("#### üìà Summary Statistics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_users = filtered_df['user_count'].sum()
        st.metric(
            label="üë• Total Users",
            value=f"{total_users:,}",
            help="Total number of users across all games and scores"
        )
    
    with col2:
        avg_score = (filtered_df['total_score'] * filtered_df['user_count']).sum() / filtered_df['user_count'].sum()
        st.metric(
            label="üéØ Average Score",
            value=f"{avg_score:.1f}",
            help="Weighted average score across all users"
        )
    
    with col3:
        max_score = filtered_df['total_score'].max()
        st.metric(
            label="üèÜ Highest Score",
            value=f"{max_score}",
            help="Maximum total score achieved"
        )
    
    with col4:
        unique_games_count = filtered_df['game_name'].nunique()
        st.metric(
            label="üéÆ Games Analyzed",
            value=f"{unique_games_count}",
            help="Number of games included in the analysis"
        )

def render_repeatability_analysis(repeatability_df: pd.DataFrame) -> None:
    """Render game repeatability analysis based on SQL query logic:
    
    SQL Query Logic:
    1. JOIN hybrid_games, hybrid_games_links, hybrid_game_completions, hybrid_profiles, hybrid_users
    2. Group by hybrid_profile_id
    3. Count distinct non-null values of game_name for each hybrid_profile_id
    4. Group by the count of distinct non-null game_name
    5. Calculate CountDistinct_hybrid_profile_id for each distinct count value
    
    Visualization:
    X-axis ‚Üí number of distinct games played (repeat count)
    Y-axis ‚Üí number of unique users (hybrid_profile_id) corresponding to each repeat count
    """
    import altair as alt
    
    if repeatability_df.empty:
        st.warning("No repeatability data available.")
        return
    
    st.markdown("### üéÆ Game Repeatability Analysis")
    
    # Create the repeatability chart with explicit axis configuration
    chart = alt.Chart(repeatability_df).mark_bar(
        cornerRadius=6,
        stroke='white',
        strokeWidth=2,
        color='#50C878'
    ).encode(
        x=alt.X('games_played:O', 
                title='No of games played', 
                axis=alt.Axis(labelAngle=0, titleFontSize=24, labelFontSize=22)),
        y=alt.Y('user_count:Q', 
                title='Number of Users', 
                axis=alt.Axis(format='~s', titleFontSize=24, labelFontSize=22)),
        tooltip=['games_played:O', 'user_count:Q']
    ).properties(
        width=800,
        height=400,
        title='User Distribution by Number of Distinct Games Completed'
    )
    
    # Add text labels
    text = alt.Chart(repeatability_df).mark_text(
        align='center',
        baseline='bottom',
        color='#2E8B57',
        fontSize=20,
        fontWeight='bold',
        dy=-10
    ).encode(
        x=alt.X('games_played:O'),
        y=alt.Y('user_count:Q'),
        text=alt.Text('user_count:Q', format='.0f')
    )
    
    # Combine chart and text
    repeatability_chart = (chart + text).configure_axis(
        grid=True
    ).configure_title(
        fontSize=28,
        fontWeight='bold'
    )
    
    st.altair_chart(repeatability_chart, use_container_width=True)
    
    # Add summary statistics based on SQL query logic
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_users = repeatability_df['user_count'].sum()
        st.metric(
            label="üë• Total Unique Users",
            value=f"{total_users:,}",
            help="Total number of unique hybrid_profile_id who completed at least one distinct game"
        )
    
    with col2:
        # Calculate weighted average of distinct games per user
        weighted_sum = (repeatability_df['games_played'] * repeatability_df['user_count']).sum()
        total_users = repeatability_df['user_count'].sum()
        avg_distinct_games_per_user = weighted_sum / total_users if total_users > 0 else 0
        st.metric(
            label="üéØ Avg Distinct Games per User",
            value=f"{avg_distinct_games_per_user:.1f}",
            help="Average number of distinct games completed per hybrid_profile_id"
        )
    
    with col3:
        max_distinct_games = repeatability_df['games_played'].max()
        st.metric(
            label="üèÜ Max Distinct Games",
            value=f"{max_distinct_games}",
            help="Maximum number of distinct games completed by a single hybrid_profile_id"
        )

def recalculate_time_series_for_games(df_main: pd.DataFrame, time_period: str) -> pd.DataFrame:
    """Recalculate time series data for selected games"""
    if df_main.empty:
        return pd.DataFrame()
    
    # Convert date to datetime (use the correct date column)
    df_main['datetime'] = pd.to_datetime(df_main['date'])
    
    # Filter to July 2nd, 2025 onwards
    july_2_2025 = pd.to_datetime('2025-07-02')
    df_main = df_main[df_main['datetime'] >= july_2_2025]
    
    time_series_data = []
    
    if time_period == "Day":
        # Day-level data (last 2 weeks from available data)
        cutoff_date = df_main['datetime'].max() - pd.Timedelta(days=14)
        df_filtered = df_main[df_main['datetime'] >= cutoff_date].copy()
        df_filtered['time_group'] = df_filtered['datetime'].dt.date
        
        for time_group in df_filtered['time_group'].unique():
            group_data = df_filtered[df_filtered['time_group'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': str(time_group),
                'period_type': 'Day',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "Week":
        # Week-level data (all available data grouped by weeks)
        # Use the earliest date in the data as the reference point
        start_date = df_main['datetime'].min()
        df_filtered = df_main.copy()
        df_filtered['days_since_start'] = (df_filtered['datetime'] - start_date).dt.days
        df_filtered['week_number'] = (df_filtered['days_since_start'] // 7) + 1
        df_filtered['time_group_week'] = 'Week ' + df_filtered['week_number'].astype(str)
        
        for time_group in df_filtered['time_group_week'].unique():
            group_data = df_filtered[df_filtered['time_group_week'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'Week',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "Month":
        # Month-level data (all available data grouped by months)
        df_filtered = df_main.copy()
        df_filtered['time_group_month'] = df_filtered['datetime'].dt.strftime('%B %Y')
        
        for time_group in df_filtered['time_group_month'].unique():
            group_data = df_filtered[df_filtered['time_group_month'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'Month',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "All time":
        # All time data (all available data grouped by months)
        # Use the same logic as Month but with different period_type
        df_filtered = df_main.copy()
        df_filtered['time_group_month'] = df_filtered['datetime'].dt.strftime('%B %Y')
        
        for time_group in df_filtered['time_group_month'].unique():
            group_data = df_filtered[df_filtered['time_group_month'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'All time',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    return pd.DataFrame(time_series_data)

def render_time_series_analysis(time_series_df: pd.DataFrame, game_conversion_df: pd.DataFrame) -> None:
    """Render time series analysis"""
    import altair as alt
    
    if time_series_df.empty:
        st.warning("No time series data available.")
        return
    
    st.markdown("### üìà Time-Series Analysis")
    
    # Create columns for filters
    ts_filter_col1, ts_filter_col2, ts_filter_col3 = st.columns(3)
    
    with ts_filter_col1:
        # Time period filter
        time_period = st.selectbox(
            "Select Time Period:",
            options=["Month", "Week", "Day"],
            help="Choose the time aggregation for the time-series graphs"
        )
    
    with ts_filter_col2:
        # Game filter for time series
        unique_games_ts = sorted(game_conversion_df['game_name'].unique())
        selected_games_ts = st.multiselect(
            "Select Games:",
            options=unique_games_ts,
            default=[],  # Empty by default - shows all games
            help="Select games to include in time series analysis. Leave empty to show all games."
        )
    
    # ts_filter_col3 reserved for future use
    
    # Use only preprocessed data (like all other graphs)
    if time_series_df.empty:
        st.warning("No time series data available.")
        return
    
    # Filter by selected time period
    filtered_ts_df = time_series_df[time_series_df['period_type'] == time_period].copy()
    
    # Apply July filter for Month view
    if time_period == "Month":
        july_onwards = ['July 2025', 'August 2025', 'September 2025', 'October 2025']
        filtered_ts_df = filtered_ts_df[filtered_ts_df['time_period'].isin(july_onwards)]
    
    # Apply game filtering if specific games are selected
    if selected_games_ts:
        # Filter by selected games
        filtered_ts_df = filtered_ts_df[filtered_ts_df['game_name'].isin(selected_games_ts)]
    
    # Aggregate data by time period to prevent overlapping points
    # Group by time_period and sum the metrics
    aggregated_df = filtered_ts_df.groupby('time_period').agg({
        'visits': 'sum',
        'users': 'sum',
        'instances': 'sum',
        'started_visits': 'sum',
        'completed_visits': 'sum',
        'started_users': 'sum',
        'completed_users': 'sum',
        'started_instances': 'sum',
        'completed_instances': 'sum'
    }).reset_index()
    
    
    if aggregated_df.empty:
        st.warning("No data available for the selected time period.")
        return
    
    # Sort the aggregated dataframe based on time period
    if time_period == "Month":
        # Convert month names to datetime for proper sorting
        try:
            aggregated_df['sort_date'] = pd.to_datetime(aggregated_df['time_period'])
            aggregated_df = aggregated_df.sort_values('sort_date').drop('sort_date', axis=1)
            # Create ordered list for Altair
            time_order = aggregated_df['time_period'].tolist()
        except Exception as e:
            # If datetime parsing fails, use original order
            st.warning(f"Could not parse dates for sorting: {e}")
            time_order = aggregated_df['time_period'].tolist()
    elif time_period == "Week":
        # Extract week number for sorting
        aggregated_df['week_num'] = aggregated_df['time_period'].str.extract(r'(\d+)').astype(int)
        aggregated_df = aggregated_df.sort_values('week_num').drop('week_num', axis=1)
        # Create ordered list for Altair
        time_order = aggregated_df['time_period'].tolist()
    elif time_period == "Day":
        # Sort by date
        try:
            aggregated_df['sort_date'] = pd.to_datetime(aggregated_df['time_period'])
            aggregated_df = aggregated_df.sort_values('sort_date').drop('sort_date', axis=1)
            # Create ordered list for Altair
            time_order = aggregated_df['time_period'].astype(str).tolist()
        except Exception as e:
            # If datetime parsing fails, use original order
            st.warning(f"Could not parse dates for sorting: {e}")
            time_order = aggregated_df['time_period'].astype(str).tolist()
    else:
        time_order = None
    
    # Create combined chart for all metrics (Completed events only)
    def create_combined_chart(data):
        """Create combined chart showing Visits, Instances, and Users together (Completed events only)"""
        chart_data = []
        for _, row in data.iterrows():
            # Add data for each metric - Using new column names
            chart_data.extend([
                {'Time': str(row['time_period']), 'Metric': 'Visits', 'Count': row['visits']},
                {'Time': str(row['time_period']), 'Metric': 'Instances', 'Count': row['instances']},
                {'Time': str(row['time_period']), 'Metric': 'Users', 'Count': row['users']}
            ])
        chart_df = pd.DataFrame(chart_data)
        
        # Create the base chart
        base = alt.Chart(chart_df).encode(
            x=alt.X('Time:N', title='Time Period', 
                   sort=time_order if time_order else None,
                   axis=alt.Axis(
                       labelAngle=0,
                       labelFontSize=12,
                       labelLimit=150,
                       titleFontSize=14
                   )),
            y=alt.Y('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            tooltip=['Time:N', 'Metric:N', 'Count:Q']
        )
        
        # Create lines for each metric
        lines = base.mark_line(
            strokeWidth=3,
            point=alt.OverlayMarkDef(
                filled=True,
                size=50,
                stroke='white',
                strokeWidth=1.5
            )
        ).encode(
            color=alt.Color('Metric:N', 
                          scale=alt.Scale(domain=['Visits', 'Instances', 'Users'],
                                        range=['#FF6B6B', '#FFA726', '#AB47BC']),
                          legend=alt.Legend(title="Metric Type", 
                                          labelFontSize=14,
                                          titleFontSize=16))
        ).properties(
            width=900,
            height=500,
            title='Time Series Analysis: Visits, Instances, and Users (Completed Events)'
        )
        
        # Add data labels for every other point to reduce clutter
        labels = base.mark_text(
            align='center',
            baseline='bottom',
            fontSize=10,
            fontWeight='bold',
            dy=-8
        ).encode(
            text=alt.Text('Count:Q', format='.0f'),
            color=alt.Color('Metric:N', 
                          scale=alt.Scale(domain=['Visits', 'Instances', 'Users'],
                                        range=['#FF6B6B', '#FFA726', '#AB47BC']),
                          legend=None)
        ).transform_filter(
            alt.datum.Time % 2 == 0  # Show labels only for every other time point
        )
        
        return (lines + labels).configure_axis(
            labelFontSize=16,
            titleFontSize=18,
            grid=True
        ).configure_title(
            fontSize=24,
            fontWeight='bold'
        )
    
    # Combined Analysis Section
    st.markdown("### üìä Time Series Analysis: Visits, Instances, and Users")
    st.markdown("This chart displays **Visits**, **Instances**, and **Users** together to show trends across all metrics using the updated calculation logic.")
    
    combined_chart = create_combined_chart(aggregated_df)
    st.altair_chart(combined_chart, use_container_width=True)
    
    # Add summary statistics
    st.markdown("#### üìà Summary Statistics")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_visits = aggregated_df['visits'].sum()
        st.metric(
            label="üîÑ Total Visits",
            value=f"{total_visits:,}",
            help="Sum of visits across the selected time period"
        )
    
    with col2:
        total_instances = aggregated_df['instances'].sum()
        st.metric(
            label="‚ö° Total Instances", 
            value=f"{total_instances:,}",
            help="Sum of instances across the selected time period"
        )
    
    with col3:
        total_users = aggregated_df['users'].sum()
        st.metric(
            label="üë• Total Users",
            value=f"{total_users:,}",
            help="Sum of users who completed events across the selected time period"
        )

def render_parent_poll_responses(poll_responses_df: pd.DataFrame, game_conversion_df: pd.DataFrame) -> None:
    """Render parent poll responses visualization"""
    import altair as alt
    
    if poll_responses_df.empty:
        st.warning("No parent poll responses data available.")
        return
    
    st.markdown("### üìä Parent Poll Responses")
    
    # Get unique games for filter
    unique_games = sorted(game_conversion_df['game_name'].unique())
    
    # Add game filter
    st.markdown("**üéÆ Game Filter:**")
    selected_games = st.multiselect(
        "Select Games for Parent Poll Analysis:",
        options=unique_games,
        default=[],  # Empty by default - shows all games
        help="Select one or more games to show parent poll responses. Leave empty to show all games."
    )
    
    # Filter data based on selected games
    if selected_games:
        # Check if game_name column exists in poll data
        if 'game_name' in poll_responses_df.columns:
            filtered_df = poll_responses_df[poll_responses_df['game_name'].isin(selected_games)]
            if filtered_df.empty:
                st.warning(f"No poll data found for selected games: {', '.join(selected_games)}")
                return
        else:
            # Fallback for data without game_name column
            filtered_df = poll_responses_df.copy()
            st.info(f"üéÆ Game filter selected: {', '.join(selected_games)} (Note: Poll data doesn't include game filtering yet)")
    else:
        filtered_df = poll_responses_df.copy()
    
    if filtered_df.empty:
        st.warning("No data available for the selected games.")
        return
    
    # Get unique questions
    unique_questions = filtered_df['question'].unique()
    
    if len(unique_questions) == 0:
        st.warning("No poll questions found in the data.")
        return
    
    # Create charts for each question
    for i, question in enumerate(unique_questions):
        st.markdown(f"#### {question}")
        
        # Filter data for this question
        question_data = filtered_df[filtered_df['question'] == question].copy()
        
        if question_data.empty:
            st.warning(f"No data available for {question}")
            continue
        
        # Create bar chart
        chart = alt.Chart(question_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#4A90E2'
        ).encode(
            x=alt.X('option:N', 
                    title='Response Option', 
                    axis=alt.Axis(
                        labelAngle=0,
                        labelFontSize=14,
                        titleFontSize=16
                    )),
            y=alt.Y('count:Q', 
                    title='Number of Responses', 
                    axis=alt.Axis(format='~s')),
            tooltip=['option:N', 'count:Q']
        ).properties(
            width=600,
            height=400,
            title=f'Responses for {question}'
        )
        
        # Add data labels
        labels = alt.Chart(question_data).mark_text(
            align='center',
            baseline='bottom',
            color='#2E8B57',
            fontSize=16,
            fontWeight='bold',
            dy=-10
        ).encode(
            x=alt.X('option:N'),
            y=alt.Y('count:Q'),
            text=alt.Text('count:Q', format='.0f')
        )
        
        # Combine chart and labels
        final_chart = (chart + labels).configure_axis(
            labelFontSize=16,
            titleFontSize=18,
            grid=True
        ).configure_title(
            fontSize=20,
            fontWeight='bold'
        )
        
        st.altair_chart(final_chart, use_container_width=True)
        
        # Add summary statistics for this question
        col1, col2, col3 = st.columns(3)
        
        with col1:
            total_responses = question_data['count'].sum()
            st.metric(
                label="üìä Total Responses",
                value=f"{total_responses:,}",
                help=f"Total number of responses for {question}"
            )
        
        with col2:
            most_popular = question_data.loc[question_data['count'].idxmax(), 'option']
            most_popular_count = question_data['count'].max()
            st.metric(
                label="üèÜ Most Popular",
                value=f"{most_popular} ({most_popular_count:,})",
                help=f"Most selected option for {question}"
            )
        
        with col3:
            unique_options = len(question_data)
            st.metric(
                label="üìù Options Available",
                value=f"{unique_options}",
                help=f"Number of response options for {question}"
            )
        
        # Add separator between questions
        if i < len(unique_questions) - 1:
            st.markdown("---")

def main() -> None:
    st.set_page_config(page_title="Hybrid Dashboard", layout="wide")
    st.title("Hybrid Dashboard")
    st.caption("Performance Optimized - Using Preprocessed Data")
    
    
    # Check if processed data exists
    check_processed_data()
    
    with st.spinner("Loading data..."):
        (summary_df, game_conversion_df, time_series_df, 
         repeatability_df, score_distribution_df, poll_responses_df, metadata) = load_processed_data()
    
    if summary_df.empty:
        st.warning("No data available.")
        return
    
    # Add filters
    st.markdown("### üéÆ Filters")
    
    # Create two columns for filters
    filter_col1, filter_col2 = st.columns(2)
    
    with filter_col1:
        # Game Name filter - get unique games from game_conversion_df
        unique_games = sorted(game_conversion_df['game_name'].unique())
        selected_games = st.multiselect(
            "Select Game Names to filter by:",
            options=unique_games,
            default=[],  # Empty by default - shows all games
            help="Select one or more games to filter the dashboard data. Leave empty to show all games."
        )
    
    with filter_col2:
        # Date filter - use metadata for correct date range
        if metadata and 'data_date_range' in metadata:
            min_date = pd.to_datetime(metadata['data_date_range']['start']).date()
            max_date = pd.to_datetime(metadata['data_date_range']['end']).date()
        else:
            min_date = pd.to_datetime('2025-07-02').date()
            # Use current date as max date
            max_date = datetime.now().date()
        
        # Create date range picker
        date_range = st.date_input(
            "Select Date Range:",
            value=(min_date, max_date),
            min_value=min_date,
            max_value=max_date,
            help="Select a date range to filter the data. Data is available from July 2nd, 2025 onwards."
        )
    
    # Show filter summary
    if len(date_range) == 2:
        date_summary = f"from {date_range[0]} to {date_range[1]}"
    elif len(date_range) == 1:
        date_summary = f"on {date_range[0]}"
    else:
        date_summary = "for all dates"
    
    # Show filter summary
    if not selected_games or len(selected_games) == len(unique_games):
        game_summary = "**All Games**"
        game_count = len(unique_games)
    else:
        game_summary = f"{', '.join(selected_games)}"
        game_count = len(selected_games)
    
    # Render conversion funnel based on game selection
    if not selected_games or len(selected_games) == len(unique_games):
        # Show total conversion funnel
        render_modern_dashboard(summary_df, summary_df)
    else:
        # Show filtered conversion funnel - use game-specific numbers
        selected_games_data = game_conversion_df[game_conversion_df['game_name'].isin(selected_games)]
        if not selected_games_data.empty:
            # Aggregate the selected games
            total_started_users = selected_games_data['started_users'].sum()
            total_completed_users = selected_games_data['completed_users'].sum()
            total_started_visits = selected_games_data['started_visits'].sum()
            total_completed_visits = selected_games_data['completed_visits'].sum()
            total_started_instances = selected_games_data['started_instances'].sum()
            total_completed_instances = selected_games_data['completed_instances'].sum()
            
            # Create summary data for selected games
            selected_games_summary = pd.DataFrame([
                {'Event': 'Started', 'Users': total_started_users, 'Visits': total_started_visits, 'Instances': total_started_instances},
                {'Event': 'Completed', 'Users': total_completed_users, 'Visits': total_completed_visits, 'Instances': total_completed_instances}
            ])
            
            render_modern_dashboard(selected_games_summary, selected_games_summary)
        else:
            st.warning("No data found for selected games.")
    
    # Add Score Distribution Analysis
    st.markdown("---")
    st.markdown("## üéØ Score Distribution Analysis")
    
    if not score_distribution_df.empty:
        render_score_distribution_chart(score_distribution_df)
    else:
        st.warning("No score distribution data available.")
    
    # Add Parent Poll Responses Analysis
    st.markdown("---")
    st.markdown("## üìä Parent Poll Responses Analysis")
    
    if not poll_responses_df.empty:
        render_parent_poll_responses(poll_responses_df, game_conversion_df)
    else:
        st.warning("No parent poll responses data available.")
    
    # Add Repeatability Analysis
    st.markdown("---")
    st.markdown("## üéÆ Game Repeatability Analysis")
    
    if not repeatability_df.empty:
        render_repeatability_analysis(repeatability_df)
    else:
        st.warning("No repeatability data available.")
    
    # Add Time Series Analysis
    st.markdown("---")
    st.markdown("## üìà Time-Series Analysis")
    
    if not time_series_df.empty:
        render_time_series_analysis(time_series_df, game_conversion_df)
    else:
        st.warning("No time series data available.")


if __name__ == "__main__":
    main()