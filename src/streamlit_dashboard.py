# âš ï¸ All data used in this dashboard must be preprocessed using preprocess_data.py before deployment.
# This dashboard only handles visualization of preprocessed data to stay within Render's 512MB memory limit.

import os
import json
import pandas as pd
import streamlit as st
from datetime import datetime
from typing import List, Tuple

# Check if processed data exists
DATA_DIR = "data"
REQUIRED_FILES = [
    "dashboard_data.csv",
    "summary_data.csv", 
    "score_distribution_data.csv",
    "time_series_data.csv",
    "repeatability_data.csv",
    "metadata.json"
]

def check_processed_data():
    """Check if all required processed data files exist"""
    missing_files = []
    for file in REQUIRED_FILES:
        file_path = os.path.join(DATA_DIR, file)
        if not os.path.exists(file_path):
            missing_files.append(file)
    
    if missing_files:
        st.error(f"ERROR: Missing processed data files: {', '.join(missing_files)}")
        st.error("WARNING: Please run 'python preprocess_data.py' locally to generate the required data files.")
        st.error("This dashboard requires preprocessed data to run efficiently on Render.")
        st.stop()
    
    return True

def load_processed_data():
    """Load all preprocessed data files"""
    try:
        # Load main data (use minimal dashboard_data.csv for filters and functionality)
        df_main = pd.DataFrame()
        if os.path.exists(os.path.join(DATA_DIR, "dashboard_data.csv")):
            df_main = pd.read_csv(os.path.join(DATA_DIR, "dashboard_data.csv"))
            df_main['server_time'] = pd.to_datetime(df_main['server_time'])
            df_main['date'] = pd.to_datetime(df_main['date'])
        elif os.path.exists(os.path.join(DATA_DIR, "processed_data.csv")):
            # Fallback to full data if available
            df_main = pd.read_csv(os.path.join(DATA_DIR, "processed_data.csv"))
            df_main['server_time'] = pd.to_datetime(df_main['server_time'])
            df_main['date'] = pd.to_datetime(df_main['date'])
        else:
            # Create a minimal dataframe for dashboard functionality
            df_main = pd.DataFrame({
                'idlink_va': [1],
                'idvisitor_converted': [1],
                'idvisit': [1],
                'server_time': [pd.Timestamp.now()],
                'idaction_name': [1],
                'custom_dimension_2': [1],
                'game_name': ['Sample Game'],
                'event': ['Started'],
                'date': [pd.Timestamp.now().date()]
            })
        
        # Load summary data
        summary_df = pd.read_csv(os.path.join(DATA_DIR, "summary_data.csv"))
        
        # Load score distribution data
        score_distribution_df = pd.DataFrame()
        if os.path.exists(os.path.join(DATA_DIR, "score_distribution_data.csv")):
            score_distribution_df = pd.read_csv(os.path.join(DATA_DIR, "score_distribution_data.csv"))
        
        # Load time series data
        time_series_df = pd.DataFrame()
        if os.path.exists(os.path.join(DATA_DIR, "time_series_data.csv")):
            time_series_df = pd.read_csv(os.path.join(DATA_DIR, "time_series_data.csv"))
        
        # Load repeatability data
        repeatability_df = pd.DataFrame()
        if os.path.exists(os.path.join(DATA_DIR, "repeatability_data.csv")):
            repeatability_df = pd.read_csv(os.path.join(DATA_DIR, "repeatability_data.csv"))
        
        # Load metadata
        metadata = {}
        if os.path.exists(os.path.join(DATA_DIR, "metadata.json")):
            with open(os.path.join(DATA_DIR, "metadata.json"), 'r') as f:
                metadata = json.load(f)
        
        return df_main, summary_df, score_distribution_df, time_series_df, repeatability_df, metadata
    
    except Exception as e:
        st.error(f"âŒ Error loading processed data: {str(e)}")
        st.error("Please ensure all data files are properly generated by running preprocess_data.py")
        st.stop()

def render_modern_dashboard(summary_df: pd.DataFrame, df_filtered: pd.DataFrame) -> None:
    """Render a modern, professional dashboard with multiple chart types"""
    import altair as alt
    
    # Add separate conversion funnels
    st.markdown("### ğŸ”„ Conversion Funnels")
    
    # Get data for each funnel
    started_users = summary_df[summary_df['Event'] == 'Started']['Users'].iloc[0]
    completed_users = summary_df[summary_df['Event'] == 'Completed']['Users'].iloc[0]
    started_visits = summary_df[summary_df['Event'] == 'Started']['Visits'].iloc[0]
    completed_visits = summary_df[summary_df['Event'] == 'Completed']['Visits'].iloc[0]
    started_instances = summary_df[summary_df['Event'] == 'Started']['Instances'].iloc[0]
    completed_instances = summary_df[summary_df['Event'] == 'Completed']['Instances'].iloc[0]
    
    # Create three separate funnels
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸ‘¥ Users Funnel")
        users_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_users, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_users, 'Order': 1}
        ])
        
        users_chart = alt.Chart(users_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#4A90E2'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        users_labels = alt.Chart(users_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        users_funnel = alt.layer(users_chart, users_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(users_funnel, use_container_width=True)
    
    with col2:
        st.markdown("#### ğŸ”„ Visits Funnel")
        visits_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_visits, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_visits, 'Order': 1}
        ])
        
        visits_chart = alt.Chart(visits_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#7ED321'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        visits_labels = alt.Chart(visits_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        visits_funnel = alt.layer(visits_chart, visits_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(visits_funnel, use_container_width=True)
    
    with col3:
        st.markdown("#### âš¡ Instances Funnel")
        instances_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_instances, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_instances, 'Order': 1}
        ])
        
        instances_chart = alt.Chart(instances_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#F5A623'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        instances_labels = alt.Chart(instances_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        instances_funnel = alt.layer(instances_chart, instances_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(instances_funnel, use_container_width=True)
    
    # Add conversion analysis
    st.markdown("### ğŸ“Š Conversion Analysis")
    
    analysis_col1, analysis_col2, analysis_col3 = st.columns(3)
    
    with analysis_col1:
        user_conversion = (completed_users / started_users * 100) if started_users > 0 else 0
        st.metric(
            label="ğŸ‘¥ User Conversion",
            value=f"{user_conversion:.1f}%",
            help=f"{completed_users:,} out of {started_users:,} users completed"
        )
    
    with analysis_col2:
        started_visits = summary_df[summary_df['Event'] == 'Started']['Visits'].iloc[0]
        completed_visits = summary_df[summary_df['Event'] == 'Completed']['Visits'].iloc[0]
        visit_conversion = (completed_visits / started_visits * 100) if started_visits > 0 else 0
        st.metric(
            label="ğŸ”„ Visit Conversion",
            value=f"{visit_conversion:.1f}%",
            help=f"{completed_visits:,} out of {started_visits:,} visits completed"
        )
    
    with analysis_col3:
        instance_conversion = (completed_instances / started_instances * 100) if started_instances > 0 else 0
        st.metric(
            label="âš¡ Instance Conversion",
            value=f"{instance_conversion:.1f}%",
            help=f"{completed_instances:,} out of {started_instances:,} instances completed"
        )

def render_score_distribution_chart(score_distribution_df: pd.DataFrame) -> None:
    """Render score distribution chart"""
    import altair as alt
    
    # Debug message
    st.info("ğŸ”§ Score Distribution Function Called - Version 1.3")
    
    if score_distribution_df.empty:
        st.warning("No score distribution data available.")
        return
    
    # Get unique games for filter
    unique_games = sorted(score_distribution_df['game_name'].unique())
    
    # Add game filter
    st.markdown("**ğŸ® Game Filter:**")
    st.info(f"Available games: {len(unique_games)} games")
    selected_games = st.multiselect(
        "Select Games for Score Distribution:",
        options=unique_games,
        default=unique_games,
        help="Select one or more games to show score distribution. Leave empty to show all games."
    )
    
    # Filter data based on selected games
    if selected_games:
        filtered_df = score_distribution_df[score_distribution_df['game_name'].isin(selected_games)]
    else:
        filtered_df = score_distribution_df
    
    if filtered_df.empty:
        st.warning("No data available for the selected games.")
        return
    
    # Create the score distribution chart
    st.markdown("### ğŸ“Š Score Distribution")
    st.markdown("This chart shows how many users achieved each total score for the selected games.")
    
    # Add combined score distribution (all games together)
    st.markdown("#### ğŸ¯ Score Distribution")
    
    # Create combined data by summing user counts across all games for each score
    combined_df = filtered_df.groupby('total_score')['user_count'].sum().reset_index()
    combined_df.columns = ['total_score', 'total_users']
    
    if not combined_df.empty:
        # Create combined bar chart
        combined_bars = alt.Chart(combined_df).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#FF6B6B'
        ).encode(
            x=alt.X('total_score:O', 
                    title='Total Score', 
                    axis=alt.Axis(
                        labelAngle=0,
                        labelFontSize=14,
                        titleFontSize=16,
                        labelLimit=100
                    )),
            y=alt.Y('total_users:Q', 
                    title='Total Number of Users', 
                    axis=alt.Axis(format='~s')),
            tooltip=['total_score:O', 'total_users:Q']
        ).properties(
            width=900,
            height=400,
            title='Score Distribution'
        )
        
        # Add data labels for combined chart
        combined_labels = alt.Chart(combined_df).mark_text(
            align='center',
            baseline='bottom',
            color='#2E8B57',
            fontSize=12,
            fontWeight='bold',
            dy=-5
        ).encode(
            x=alt.X('total_score:O'),
            y=alt.Y('total_users:Q'),
            text=alt.Text('total_users:Q', format='.0f')
        )
        
        # Combine bars and labels for combined chart
        combined_chart = (combined_bars + combined_labels).configure_axis(
            labelFontSize=16,
            titleFontSize=18,
            grid=True
        ).configure_title(
            fontSize=24,
            fontWeight='bold'
        )
        
        st.altair_chart(combined_chart, use_container_width=True)
    
    # Add summary statistics after the chart
    st.markdown("#### ğŸ“ˆ Summary Statistics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_users = filtered_df['user_count'].sum()
        st.metric(
            label="ğŸ‘¥ Total Users",
            value=f"{total_users:,}",
            help="Total number of users across all games and scores"
        )
    
    with col2:
        avg_score = (filtered_df['total_score'] * filtered_df['user_count']).sum() / filtered_df['user_count'].sum()
        st.metric(
            label="ğŸ¯ Average Score",
            value=f"{avg_score:.1f}",
            help="Weighted average score across all users"
        )
    
    with col3:
        max_score = filtered_df['total_score'].max()
        st.metric(
            label="ğŸ† Highest Score",
            value=f"{max_score}",
            help="Maximum total score achieved"
        )
    
    with col4:
        unique_games_count = filtered_df['game_name'].nunique()
        st.metric(
            label="ğŸ® Games Analyzed",
            value=f"{unique_games_count}",
            help="Number of games included in the analysis"
        )

def render_repeatability_analysis(repeatability_df: pd.DataFrame) -> None:
    """Render game repeatability analysis"""
    import altair as alt
    
    if repeatability_df.empty:
        st.warning("No repeatability data available.")
        return
    
    st.markdown("### ğŸ® Game Repeatability Analysis")
    
    # Create the repeatability chart
    bars = alt.Chart(repeatability_df).mark_bar(
        cornerRadius=6,
        stroke='white',
        strokeWidth=2,
        color='#50C878'
    ).encode(
        x=alt.X('games_played:O', title='Number of Games Played', axis=alt.Axis(labelAngle=0)),
        y=alt.Y('user_count:Q', title='Number of Users', axis=alt.Axis(format='~s')),
        tooltip=['games_played:O', 'user_count:Q']
    ).properties(
        width=800,
        height=400,
        title='User Distribution by Number of Games Completed'
    )
    
    # Add data labels on top of bars
    labels = alt.Chart(repeatability_df).mark_text(
        align='center',
        baseline='bottom',
        color='#2E8B57',
        fontSize=20,
        fontWeight='bold',
        dy=-10
    ).encode(
        x=alt.X('games_played:O'),
        y=alt.Y('user_count:Q'),
        text=alt.Text('user_count:Q', format='.0f')
    )
    
    # Combine bars and labels
    repeatability_chart = (bars + labels).configure_axis(
        labelFontSize=22,
        titleFontSize=24,
        grid=True
    ).configure_title(
        fontSize=28,
        fontWeight='bold'
    )
    
    st.altair_chart(repeatability_chart, use_container_width=True)
    
    # Add summary statistics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_users = repeatability_df['user_count'].sum()
        st.metric(
            label="ğŸ‘¥ Total Users (Completed)",
            value=f"{total_users:,}",
            help="Total number of users who completed at least one game"
        )
    
    with col2:
        # Calculate weighted average
        weighted_sum = (repeatability_df['games_played'] * repeatability_df['user_count']).sum()
        total_users = repeatability_df['user_count'].sum()
        avg_games_per_user = weighted_sum / total_users if total_users > 0 else 0
        st.metric(
            label="ğŸ¯ Avg Games per User",
            value=f"{avg_games_per_user:.1f}",
            help="Average number of games completed per user"
        )
    
    with col3:
        max_games_played = repeatability_df['games_played'].max()
        st.metric(
            label="ğŸ† Max Games Played",
            value=f"{max_games_played}",
            help="Maximum number of games completed by a single user"
        )

def recalculate_time_series_for_games(df_main: pd.DataFrame, time_period: str) -> pd.DataFrame:
    """Recalculate time series data for selected games"""
    if df_main.empty:
        return pd.DataFrame()
    
    # Convert server_time to datetime
    df_main['datetime'] = pd.to_datetime(df_main['server_time'])
    
    time_series_data = []
    
    if time_period == "Day":
        # Day-level data (last 2 weeks from July 2nd, 2025 onwards)
        cutoff_date = df_main['datetime'].max() - pd.Timedelta(days=14)
        df_filtered = df_main[df_main['datetime'] >= cutoff_date].copy()
        df_filtered['time_group'] = df_filtered['datetime'].dt.date
        
        for time_group in df_filtered['time_group'].unique():
            group_data = df_filtered[df_filtered['time_group'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': str(time_group),
                'period_type': 'Day',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "Week":
        # Week-level data (last 2 weeks only)
        cutoff_date = df_main['datetime'].max() - pd.Timedelta(days=14)
        df_filtered = df_main[df_main['datetime'] >= cutoff_date].copy()
        july_2_2025 = pd.Timestamp('2025-07-02')
        df_filtered['days_since_july_2'] = (df_filtered['datetime'] - july_2_2025).dt.days
        df_filtered['week_number'] = (df_filtered['days_since_july_2'] // 7) + 1
        df_filtered['time_group_week'] = 'Week ' + df_filtered['week_number'].astype(str)
        
        for time_group in df_filtered['time_group_week'].unique():
            group_data = df_filtered[df_filtered['time_group_week'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'Week',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "Month":
        # Month-level data (all data from July 2nd, 2025 onwards)
        df_main['time_group_month'] = df_main['datetime'].dt.strftime('%B %Y')
        
        for time_group in df_main['time_group_month'].unique():
            group_data = df_main[df_main['time_group_month'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'Month',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "All time":
        # All time data (all data from July 2nd, 2025 onwards)
        # Use the same logic as Month but with different period_type
        df_main['time_group_month'] = df_main['datetime'].dt.strftime('%B %Y')
        
        for time_group in df_main['time_group_month'].unique():
            group_data = df_main[df_main['time_group_month'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'All time',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    return pd.DataFrame(time_series_data)

def render_time_series_analysis(time_series_df: pd.DataFrame) -> None:
    """Render time series analysis"""
    import altair as alt
    
    if time_series_df.empty:
        st.warning("No time series data available.")
        return
    
    st.markdown("### ğŸ“ˆ Time-Series Analysis")
    st.info("ğŸ“… Time series data shows activity from July 2nd, 2025 onwards")
    
    # Create columns for filters
    ts_filter_col1, ts_filter_col2, ts_filter_col3 = st.columns(3)
    
    with ts_filter_col1:
        # Time period filter
        time_period = st.selectbox(
            "Select Time Period:",
            options=["All time", "Month", "Week", "Day"],
            help="Choose the time aggregation for the time-series graphs"
        )
    
    with ts_filter_col2:
        # Game filter for time series
        # Load main data to get game names for filtering
        df_main, _, _, _, _, _ = load_processed_data()
        unique_games_ts = sorted(df_main['game_name'].unique())
        selected_games_ts = st.multiselect(
            "Select Games:",
            options=unique_games_ts,
            default=unique_games_ts,
            help="Select games to include in time series analysis"
        )
    
    with ts_filter_col3:
        # Show data info
        st.info(f"ğŸ“Š Showing {len(time_series_df)} time periods")
    
    # Filter data based on selected time period
    if time_period == "All time":
        # For "All time", show all available data (which is already filtered to July 2nd, 2025 onwards)
        filtered_ts_df = time_series_df
    else:
        filtered_ts_df = time_series_df[time_series_df['period_type'] == time_period]
    
    if filtered_ts_df.empty:
        st.warning("No data available for the selected time period.")
        return
    
    # Apply game filtering by recalculating metrics from main data
    if selected_games_ts and 'All Games' not in selected_games_ts:
        st.info(f"ğŸ® Filtering time series for selected games: {', '.join(selected_games_ts)}")
        
        # Get filtered main data for the selected games
        df_main_filtered = df_main[df_main['game_name'].isin(selected_games_ts)]
        
        # Recalculate time series data for selected games
        filtered_ts_df = recalculate_time_series_for_games(df_main_filtered, time_period)
        
        if filtered_ts_df.empty:
            st.warning("No data available for the selected games and time period.")
            return
    
    # Sort the dataframe based on time period
    if time_period == "Month" or time_period == "All time":
        # Convert month names to datetime for proper sorting
        filtered_ts_df['sort_date'] = pd.to_datetime(filtered_ts_df['time_period'])
        filtered_ts_df = filtered_ts_df.sort_values('sort_date').drop('sort_date', axis=1)
        # Create ordered list for Altair
        time_order = filtered_ts_df['time_period'].tolist()
    elif time_period == "Week":
        # Extract week number for sorting
        filtered_ts_df['week_num'] = filtered_ts_df['time_period'].str.extract(r'(\d+)').astype(int)
        filtered_ts_df = filtered_ts_df.sort_values('week_num').drop('week_num', axis=1)
        # Create ordered list for Altair
        time_order = filtered_ts_df['time_period'].tolist()
    elif time_period == "Day":
        # Sort by date
        filtered_ts_df['sort_date'] = pd.to_datetime(filtered_ts_df['time_period'])
        filtered_ts_df = filtered_ts_df.sort_values('sort_date').drop('sort_date', axis=1)
        # Create ordered list for Altair
        time_order = filtered_ts_df['time_period'].astype(str).tolist()
    else:
        time_order = None
    
    # Create three separate graphs stacked vertically
    
    # Users Chart
    st.markdown("#### ğŸ‘¥ Users Over Time")
    
    # Prepare data for users chart
    users_data = []
    for _, row in filtered_ts_df.iterrows():
        users_data.extend([
            {'Time': str(row['time_period']), 'Event': 'Started', 'Count': row['started_users']},
            {'Time': str(row['time_period']), 'Event': 'Completed', 'Count': row['completed_users']}
        ])
    users_chart_df = pd.DataFrame(users_data)
    
    # Create line chart for users with data labels
    users_lines = alt.Chart(users_chart_df).mark_line(
        strokeWidth=4,
        point=alt.OverlayMarkDef(
            filled=True,
            size=100,
            stroke='white',
            strokeWidth=2
        )
    ).encode(
        x=alt.X('Time:N', title='Time Period', 
               sort=time_order if time_order else None,
               axis=alt.Axis(
                   labelAngle=0,
                   labelFontSize=14,
                   labelLimit=200,
                   titleFontSize=16
               )),
        y=alt.Y('Count:Q', title='Number of Users', axis=alt.Axis(format='~s')),
        color=alt.Color('Event:N', 
                      scale=alt.Scale(domain=['Started', 'Completed'], 
                                    range=['#FF6B6B', '#4ECDC4']),
                      legend=alt.Legend(title="Event Type")),
        tooltip=['Time:N', 'Event:N', 'Count:Q']
    ).properties(
        width=900,
        height=400,
        title='Users: Started vs Completed'
    )
    
    # Add data labels for line chart with proper positioning
    users_started_labels = alt.Chart(users_chart_df[users_chart_df['Event'] == 'Started']).mark_text(
        align='center',
        baseline='bottom',
        color='#FF6B6B',
        fontSize=14,
        fontWeight='bold',
        dy=-15
    ).encode(
        x=alt.X('Time:N', sort=time_order if time_order else None),
        y=alt.Y('Count:Q'),
        text=alt.Text('Count:Q', format='.0f')
    )
    
    users_completed_labels = alt.Chart(users_chart_df[users_chart_df['Event'] == 'Completed']).mark_text(
        align='center',
        baseline='top',
        color='#4ECDC4',
        fontSize=14,
        fontWeight='bold',
        dy=15
    ).encode(
        x=alt.X('Time:N', sort=time_order if time_order else None),
        y=alt.Y('Count:Q'),
        text=alt.Text('Count:Q', format='.0f')
    )
    
    users_chart = (users_lines + users_started_labels + users_completed_labels)
    
    users_chart = users_chart.configure_axis(
        labelFontSize=18,
        titleFontSize=20,
        grid=True
    ).configure_title(
        fontSize=24,
        fontWeight='bold'
    )
    
    st.altair_chart(users_chart, use_container_width=True)
    
    # Visits Chart
    st.markdown("#### ğŸ”„ Visits Over Time")
    
    # Prepare data for visits chart
    visits_data = []
    for _, row in filtered_ts_df.iterrows():
        visits_data.extend([
            {'Time': str(row['time_period']), 'Event': 'Started', 'Count': row['started_visits']},
            {'Time': str(row['time_period']), 'Event': 'Completed', 'Count': row['completed_visits']}
        ])
    visits_chart_df = pd.DataFrame(visits_data)
    
    # Create line chart for visits with data labels
    visits_lines = alt.Chart(visits_chart_df).mark_line(
        strokeWidth=4,
        point=alt.OverlayMarkDef(
            filled=True,
            size=100,
            stroke='white',
            strokeWidth=2
        )
    ).encode(
        x=alt.X('Time:N', title='Time Period', 
               sort=time_order if time_order else None,
               axis=alt.Axis(
                   labelAngle=0,
                   labelFontSize=14,
                   labelLimit=200,
                   titleFontSize=16
               )),
        y=alt.Y('Count:Q', title='Number of Visits', axis=alt.Axis(format='~s')),
        color=alt.Color('Event:N', 
                      scale=alt.Scale(domain=['Started', 'Completed'], 
                                    range=['#FF6B6B', '#4ECDC4']),
                      legend=alt.Legend(title="Event Type")),
        tooltip=['Time:N', 'Event:N', 'Count:Q']
    ).properties(
        width=900,
        height=400,
        title='Visits: Started vs Completed'
    )
    
    # Add data labels for line chart with proper positioning
    visits_started_labels = alt.Chart(visits_chart_df[visits_chart_df['Event'] == 'Started']).mark_text(
        align='center',
        baseline='bottom',
        color='#FF6B6B',
        fontSize=14,
        fontWeight='bold',
        dy=-15
    ).encode(
        x=alt.X('Time:N', sort=time_order if time_order else None),
        y=alt.Y('Count:Q'),
        text=alt.Text('Count:Q', format='.0f')
    )
    
    visits_completed_labels = alt.Chart(visits_chart_df[visits_chart_df['Event'] == 'Completed']).mark_text(
        align='center',
        baseline='top',
        color='#4ECDC4',
        fontSize=14,
        fontWeight='bold',
        dy=15
    ).encode(
        x=alt.X('Time:N', sort=time_order if time_order else None),
        y=alt.Y('Count:Q'),
        text=alt.Text('Count:Q', format='.0f')
    )
    
    visits_chart = (visits_lines + visits_started_labels + visits_completed_labels).configure_axis(
        labelFontSize=18,
        titleFontSize=20,
        grid=True
    ).configure_title(
        fontSize=24,
        fontWeight='bold'
    )
    
    st.altair_chart(visits_chart, use_container_width=True)
    
    # Instances Chart
    st.markdown("#### âš¡ Instances Over Time")
    
    # Prepare data for instances chart
    instances_data = []
    for _, row in filtered_ts_df.iterrows():
        instances_data.extend([
            {'Time': str(row['time_period']), 'Event': 'Started', 'Count': row['started_instances']},
            {'Time': str(row['time_period']), 'Event': 'Completed', 'Count': row['completed_instances']}
        ])
    instances_chart_df = pd.DataFrame(instances_data)
    
    # Create line chart for instances with data labels
    instances_lines = alt.Chart(instances_chart_df).mark_line(
        strokeWidth=4,
        point=alt.OverlayMarkDef(
            filled=True,
            size=100,
            stroke='white',
            strokeWidth=2
        )
    ).encode(
        x=alt.X('Time:N', title='Time Period', 
               sort=time_order if time_order else None,
               axis=alt.Axis(
                   labelAngle=0,
                   labelFontSize=14,
                   labelLimit=200,
                   titleFontSize=16
               )),
        y=alt.Y('Count:Q', title='Number of Instances', axis=alt.Axis(format='~s')),
        color=alt.Color('Event:N', 
                      scale=alt.Scale(domain=['Started', 'Completed'], 
                                    range=['#FF6B6B', '#4ECDC4']),
                      legend=alt.Legend(title="Event Type")),
        tooltip=['Time:N', 'Event:N', 'Count:Q']
    ).properties(
        width=900,
        height=400,
        title='Instances: Started vs Completed'
    )
    
    # Add data labels for line chart with proper positioning
    instances_started_labels = alt.Chart(instances_chart_df[instances_chart_df['Event'] == 'Started']).mark_text(
        align='center',
        baseline='bottom',
        color='#FF6B6B',
        fontSize=14,
        fontWeight='bold',
        dy=-15
    ).encode(
        x=alt.X('Time:N', sort=time_order if time_order else None),
        y=alt.Y('Count:Q'),
        text=alt.Text('Count:Q', format='.0f')
    )
    
    instances_completed_labels = alt.Chart(instances_chart_df[instances_chart_df['Event'] == 'Completed']).mark_text(
        align='center',
        baseline='top',
        color='#4ECDC4',
        fontSize=14,
        fontWeight='bold',
        dy=15
    ).encode(
        x=alt.X('Time:N', sort=time_order if time_order else None),
        y=alt.Y('Count:Q'),
        text=alt.Text('Count:Q', format='.0f')
    )
    
    instances_chart = (instances_lines + instances_started_labels + instances_completed_labels).configure_axis(
        labelFontSize=18,
        titleFontSize=20,
        grid=True
    ).configure_title(
        fontSize=24,
        fontWeight='bold'
    )
    
    st.altair_chart(instances_chart, use_container_width=True)

def main() -> None:
    st.set_page_config(page_title="Matomo Events Dashboard", layout="wide")
    st.title("Matomo Events Dashboard")
    st.caption("All data (server_time adjusted by +5h30m) | Version: 1.3")
    
    # Check if processed data exists
    check_processed_data()
    
    with st.spinner("Loading preprocessed data..."):
        df_main, summary_df, score_distribution_df, time_series_df, repeatability_df, metadata = load_processed_data()
    
    if df_main.empty:
        st.warning("No data available.")
        return
    
    # Show data info
    if metadata:
        st.info(f"ğŸ“Š Data last updated: {metadata.get('preprocessing_date', 'Unknown')} | Records: {metadata.get('main_data_records', 'Unknown')}")
    
    # Add filters
    st.markdown("### ğŸ® Filters")
    
    # Create two columns for filters
    filter_col1, filter_col2 = st.columns(2)
    
    with filter_col1:
        # Game Name filter
        unique_games = sorted(df_main['game_name'].unique())
        selected_games = st.multiselect(
            "Select Game Names to filter by:",
            options=unique_games,
            default=unique_games,  # Show all games by default
            help="Select one or more games to filter the dashboard data. Leave empty to show all games."
        )
    
    with filter_col2:
        # Date filter
        # Set minimum date to July 2nd, 2025
        min_date = pd.to_datetime('2025-07-02').date()
        max_date = df_main['date'].max()
        
        # Create date range picker
        date_range = st.date_input(
            "Select Date Range:",
            value=(min_date, max_date),
            min_value=min_date,
            max_value=max_date,
            help="Select a date range to filter the data. The server_time is already adjusted by +5h30m. Data is available from July 2nd, 2025 onwards."
        )
    
    # Apply filters
    df_filtered = df_main.copy()
    
    # Apply game filter
    if selected_games:
        df_filtered = df_filtered[df_filtered['game_name'].isin(selected_games)]
    
    # Apply date filter
    if len(date_range) == 2:  # Both start and end date selected
        start_date, end_date = date_range
        # Convert date column to datetime for proper comparison
        df_filtered['date'] = pd.to_datetime(df_filtered['date']).dt.date
        df_filtered = df_filtered[
            (df_filtered['date'] >= start_date) & 
            (df_filtered['date'] <= end_date)
        ]
    elif len(date_range) == 1:  # Only one date selected
        # Convert date column to datetime for proper comparison
        df_filtered['date'] = pd.to_datetime(df_filtered['date']).dt.date
        df_filtered = df_filtered[df_filtered['date'] == date_range[0]]
    
    if df_filtered.empty:
        st.warning("No data available for the selected filters.")
        return
    
    # Show filter summary
    if len(date_range) == 2:
        date_summary = f"from {date_range[0]} to {date_range[1]}"
    elif len(date_range) == 1:
        date_summary = f"on {date_range[0]}"
    else:
        date_summary = "for all dates"
    
    st.info(f"ğŸ“Š Showing data for {len(selected_games)} selected game(s): {', '.join(selected_games)} | Date range: {date_summary}")

    # Use the original summary data for conversion funnel (not recalculated from filtered data)
    # The summary_data.csv contains the correct total numbers for the entire dataset
    render_modern_dashboard(summary_df, df_filtered)
    
    # Add Score Distribution Analysis
    st.markdown("---")
    st.markdown("## ğŸ¯ Score Distribution Analysis")
    
    if not score_distribution_df.empty:
        render_score_distribution_chart(score_distribution_df)
    else:
        st.warning("No score distribution data available.")
    
    # Add Repeatability Analysis
    st.markdown("---")
    st.markdown("## ğŸ® Game Repeatability Analysis")
    
    if not repeatability_df.empty:
        render_repeatability_analysis(repeatability_df)
    else:
        st.warning("No repeatability data available.")
    
    # Add Time Series Analysis
    st.markdown("---")
    st.markdown("## ğŸ“ˆ Time-Series Analysis")
    
    if not time_series_df.empty:
        render_time_series_analysis(time_series_df)
    else:
        st.warning("No time series data available.")


if __name__ == "__main__":
    main()