# âš ï¸ All data used in this dashboard must be preprocessed using master_processor.py before deployment.
# This dashboard only handles visualization of preprocessed data to stay within Render's 512MB memory limit.

import os
import json
import pandas as pd
import streamlit as st
from datetime import datetime
from typing import List, Tuple

# Use preprocess_data.py directly instead of processed CSV files
DATA_DIR = "data"
REQUIRED_FILES = [
    "dashboard_data.csv",
    "summary_data.csv",
    "time_series_data.csv",
    "repeatability_data.csv",
    "score_distribution_data.csv"
]

def check_processed_data():
    """Check if all required processed data files exist"""
    # Check if DATA_DIR exists
    if not os.path.exists(DATA_DIR):
        st.error(f"ERROR: Data directory does not exist: {DATA_DIR}")
        st.error("Please ensure data folder is uploaded to GitHub.")
        st.stop()
    
    missing_files = []
    for file in REQUIRED_FILES:
        file_path = os.path.join(DATA_DIR, file)
        if not os.path.exists(file_path):
            missing_files.append(file)
    
    if missing_files:
        st.error(f"ERROR: Missing processed data files: {', '.join(missing_files)}")
        st.error(f"Looking in directory: {DATA_DIR}")
        st.error("WARNING: Please run 'python preprocess_data.py' locally to generate the required data files.")
        st.stop()
    
    return True

def load_processed_data():
    """Load all data files from data/ directory"""
    try:
        # Load main dashboard data
        df_main = pd.read_csv(os.path.join(DATA_DIR, "dashboard_data.csv"))
        
        # Load summary data for conversion funnels
        summary_df = pd.read_csv(os.path.join(DATA_DIR, "summary_data.csv"))
        
        # Load time series data
        time_series_df = pd.read_csv(os.path.join(DATA_DIR, "time_series_data.csv"))
        
        # Load repeatability data
        repeatability_df = pd.read_csv(os.path.join(DATA_DIR, "repeatability_data.csv"))
        
        # Load score distribution data
        score_distribution_df = pd.read_csv(os.path.join(DATA_DIR, "score_distribution_data.csv"))
        
        # Create metadata
        metadata = {
            'last_updated': datetime.now().isoformat(),
            'data_source': 'data',
            'version': '2.0'
        }
        
        return (df_main, summary_df, time_series_df, 
                repeatability_df, score_distribution_df, metadata)
    
    except Exception as e:
        st.error(f"âŒ Error loading processed data: {str(e)}")
        st.error("Please ensure all data files are properly generated by running preprocess_data.py")
        st.stop()

def render_modern_dashboard(conversion_df: pd.DataFrame, df_filtered: pd.DataFrame) -> None:
    """Render a modern, professional dashboard with multiple chart types"""
    import altair as alt
    
    # Add separate conversion funnels
    st.markdown("### ðŸ”„ Conversion Funnels")
    
    # Get data for each funnel from conversion data
    if 'game_name' in conversion_df.columns:
        # Game-specific data - aggregate across selected games
        if 'Event' in conversion_df.columns:
            # Summary data format
            started_users = conversion_df[conversion_df['Event'] == 'Started']['Users'].sum()
            completed_users = conversion_df[conversion_df['Event'] == 'Completed']['Users'].sum()
            started_visits = conversion_df[conversion_df['Event'] == 'Started']['Visits'].sum()
            completed_visits = conversion_df[conversion_df['Event'] == 'Completed']['Visits'].sum()
            started_instances = conversion_df[conversion_df['Event'] == 'Started']['Instances'].sum()
            completed_instances = conversion_df[conversion_df['Event'] == 'Completed']['Instances'].sum()
        else:
            # Dashboard data format - calculate from raw data
            started_users = conversion_df[conversion_df['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = conversion_df[conversion_df['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = conversion_df[conversion_df['event'] == 'Started']['idvisit'].nunique()
            completed_visits = conversion_df[conversion_df['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(conversion_df[conversion_df['event'] == 'Started'])
            completed_instances = len(conversion_df[conversion_df['event'] == 'Completed'])
    else:
        # Total data - get direct values
        started_users = conversion_df[conversion_df['Event'] == 'Started']['Users'].iloc[0]
        completed_users = conversion_df[conversion_df['Event'] == 'Completed']['Users'].iloc[0]
        started_visits = conversion_df[conversion_df['Event'] == 'Started']['Visits'].iloc[0]
        completed_visits = conversion_df[conversion_df['Event'] == 'Completed']['Visits'].iloc[0]
        started_instances = conversion_df[conversion_df['Event'] == 'Started']['Instances'].iloc[0]
        completed_instances = conversion_df[conversion_df['Event'] == 'Completed']['Instances'].iloc[0]
    
    
    # Create three separate funnels
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ðŸ‘¥ Users Funnel")
        users_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_users, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_users, 'Order': 1}
        ])
        
        users_chart = alt.Chart(users_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#4A90E2'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        users_labels = alt.Chart(users_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        users_funnel = alt.layer(users_chart, users_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(users_funnel, use_container_width=True)
    
    with col2:
        st.markdown("#### ðŸ”„ Visits Funnel")
        visits_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_visits, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_visits, 'Order': 1}
        ])
        
        visits_chart = alt.Chart(visits_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#7ED321'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        visits_labels = alt.Chart(visits_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        visits_funnel = alt.layer(visits_chart, visits_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(visits_funnel, use_container_width=True)
    
    with col3:
        st.markdown("#### âš¡ Instances Funnel")
        instances_data = pd.DataFrame([
            {'Stage': 'Started', 'Count': started_instances, 'Order': 0},
            {'Stage': 'Completed', 'Count': completed_instances, 'Order': 1}
        ])
        
        instances_chart = alt.Chart(instances_data).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#F5A623'
        ).encode(
            x=alt.X('Count:Q', title='Count', axis=alt.Axis(format='~s')),
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending'), title=''),
            opacity=alt.condition(
                alt.datum.Stage == 'Started',
                alt.value(0.8),
                alt.value(1.0)
            ),
            tooltip=['Stage:N', 'Count:Q']
        ).properties(
            width=300,
            height=200
        )
        
        # Add labels with complete numbers - positioned at the start of bars
        instances_labels = alt.Chart(instances_data).mark_text(
            align='left',
            baseline='middle',
            color='white',
            fontSize=22,
            fontWeight='bold',
            dx=10
        ).encode(
            x=alt.value(10),  # Fixed position at the start
            y=alt.Y('Stage:N', sort=alt.SortField(field='Order', order='ascending')),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        instances_funnel = alt.layer(instances_chart, instances_labels).configure_view(
            strokeWidth=0
        ).configure_axis(
            labelFontSize=22,
            titleFontSize=24,
            grid=False
        )
        
        st.altair_chart(instances_funnel, use_container_width=True)
    
    # Add conversion analysis
    st.markdown("### ðŸ“Š Conversion Analysis")
    
    analysis_col1, analysis_col2, analysis_col3 = st.columns(3)
    
    with analysis_col1:
        user_conversion = (completed_users / started_users * 100) if started_users > 0 else 0
        st.metric(
            label="ðŸ‘¥ User Conversion",
            value=f"{user_conversion:.1f}%",
            help=f"{completed_users:,} out of {started_users:,} users completed"
        )
    
    with analysis_col2:
        visit_conversion = (completed_visits / started_visits * 100) if started_visits > 0 else 0
        st.metric(
            label="ðŸ”„ Visit Conversion",
            value=f"{visit_conversion:.1f}%",
            help=f"{completed_visits:,} out of {started_visits:,} visits completed"
        )
    
    with analysis_col3:
        instance_conversion = (completed_instances / started_instances * 100) if started_instances > 0 else 0
        st.metric(
            label="âš¡ Instance Conversion",
            value=f"{instance_conversion:.1f}%",
            help=f"{completed_instances:,} out of {started_instances:,} instances completed"
        )

def render_score_distribution_chart(score_distribution_df: pd.DataFrame) -> None:
    """Render score distribution chart"""
    import altair as alt
    
    
    if score_distribution_df.empty:
        st.warning("No score distribution data available.")
        return
    
    # Get unique games for filter
    unique_games = sorted(score_distribution_df['game_name'].unique())
    
    # Add game filter
    st.markdown("**ðŸŽ® Game Filter:**")
    selected_games = st.multiselect(
        "Select Games for Score Distribution:",
        options=unique_games,
        default=[],  # Empty by default - shows all games
        help="Select one or more games to show score distribution. Leave empty to show all games."
    )
    
    # Filter data based on selected games
    if selected_games:
        filtered_df = score_distribution_df[score_distribution_df['game_name'].isin(selected_games)]
    else:
        # Empty selection means all games
        filtered_df = score_distribution_df
    
    if filtered_df.empty:
        st.warning("No data available for the selected games.")
        return
    
    # Create the score distribution chart
    st.markdown("### ðŸ“Š Score Distribution")
    st.markdown("This chart shows how many users achieved each total score for the selected games.")
    
    # Add combined score distribution (all games together)
    st.markdown("#### ðŸŽ¯ Score Distribution")
    
    # Create combined data by summing user counts across all games for each score
    combined_df = filtered_df.groupby('total_score')['user_count'].sum().reset_index()
    combined_df.columns = ['total_score', 'total_users']
    
    if not combined_df.empty:
        # Create combined bar chart
        combined_bars = alt.Chart(combined_df).mark_bar(
            cornerRadius=6,
            stroke='white',
            strokeWidth=2,
            color='#FF6B6B'
        ).encode(
            x=alt.X('total_score:O', 
                    title='Total Score', 
                    axis=alt.Axis(
                        labelAngle=0,
                        labelFontSize=14,
                        titleFontSize=16,
                        labelLimit=100
                    )),
            y=alt.Y('total_users:Q', 
                    title='Total Number of Users', 
                    axis=alt.Axis(format='~s')),
            tooltip=['total_score:O', 'total_users:Q']
        ).properties(
            width=900,
            height=400,
            title='Score Distribution'
        )
        
        # Add data labels for combined chart
        combined_labels = alt.Chart(combined_df).mark_text(
            align='center',
            baseline='bottom',
            color='#2E8B57',
            fontSize=12,
            fontWeight='bold',
            dy=-5
        ).encode(
            x=alt.X('total_score:O'),
            y=alt.Y('total_users:Q'),
            text=alt.Text('total_users:Q', format='.0f')
        )
        
        # Combine bars and labels for combined chart
        combined_chart = (combined_bars + combined_labels).configure_axis(
            labelFontSize=16,
            titleFontSize=18,
            grid=True
        ).configure_title(
            fontSize=24,
            fontWeight='bold'
        )
        
        st.altair_chart(combined_chart, use_container_width=True)
    
    # Add summary statistics after the chart
    st.markdown("#### ðŸ“ˆ Summary Statistics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_users = filtered_df['user_count'].sum()
        st.metric(
            label="ðŸ‘¥ Total Users",
            value=f"{total_users:,}",
            help="Total number of users across all games and scores"
        )
    
    with col2:
        avg_score = (filtered_df['total_score'] * filtered_df['user_count']).sum() / filtered_df['user_count'].sum()
        st.metric(
            label="ðŸŽ¯ Average Score",
            value=f"{avg_score:.1f}",
            help="Weighted average score across all users"
        )
    
    with col3:
        max_score = filtered_df['total_score'].max()
        st.metric(
            label="ðŸ† Highest Score",
            value=f"{max_score}",
            help="Maximum total score achieved"
        )
    
    with col4:
        unique_games_count = filtered_df['game_name'].nunique()
        st.metric(
            label="ðŸŽ® Games Analyzed",
            value=f"{unique_games_count}",
            help="Number of games included in the analysis"
        )

def render_repeatability_analysis(repeatability_df: pd.DataFrame) -> None:
    """Render game repeatability analysis based on SQL query logic:
    
    SQL Query Logic:
    1. JOIN hybrid_games, hybrid_games_links, hybrid_game_completions, hybrid_profiles, hybrid_users
    2. Group by hybrid_profile_id
    3. Count distinct non-null values of game_name for each hybrid_profile_id
    4. Group by the count of distinct non-null game_name
    5. Calculate CountDistinct_hybrid_profile_id for each distinct count value
    
    Visualization:
    X-axis â†’ number of distinct games played (repeat count)
    Y-axis â†’ number of unique users (hybrid_profile_id) corresponding to each repeat count
    """
    import altair as alt
    
    if repeatability_df.empty:
        st.warning("No repeatability data available.")
        return
    
    st.markdown("### ðŸŽ® Game Repeatability Analysis")
    
    # Create the repeatability chart with explicit axis configuration
    chart = alt.Chart(repeatability_df).mark_bar(
        cornerRadius=6,
        stroke='white',
        strokeWidth=2,
        color='#50C878'
    ).encode(
        x=alt.X('games_played:O', 
                title='No of games played', 
                axis=alt.Axis(labelAngle=0, titleFontSize=24, labelFontSize=22)),
        y=alt.Y('user_count:Q', 
                title='Number of Users', 
                axis=alt.Axis(format='~s', titleFontSize=24, labelFontSize=22)),
        tooltip=['games_played:O', 'user_count:Q']
    ).properties(
        width=800,
        height=400,
        title='User Distribution by Number of Distinct Games Completed'
    )
    
    # Add text labels
    text = alt.Chart(repeatability_df).mark_text(
        align='center',
        baseline='bottom',
        color='#2E8B57',
        fontSize=20,
        fontWeight='bold',
        dy=-10
    ).encode(
        x=alt.X('games_played:O'),
        y=alt.Y('user_count:Q'),
        text=alt.Text('user_count:Q', format='.0f')
    )
    
    # Combine chart and text
    repeatability_chart = (chart + text).configure_axis(
        grid=True
    ).configure_title(
        fontSize=28,
        fontWeight='bold'
    )
    
    st.altair_chart(repeatability_chart, use_container_width=True)
    
    # Add summary statistics based on SQL query logic
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_users = repeatability_df['user_count'].sum()
        st.metric(
            label="ðŸ‘¥ Total Unique Users",
            value=f"{total_users:,}",
            help="Total number of unique hybrid_profile_id who completed at least one distinct game"
        )
    
    with col2:
        # Calculate weighted average of distinct games per user
        weighted_sum = (repeatability_df['games_played'] * repeatability_df['user_count']).sum()
        total_users = repeatability_df['user_count'].sum()
        avg_distinct_games_per_user = weighted_sum / total_users if total_users > 0 else 0
        st.metric(
            label="ðŸŽ¯ Avg Distinct Games per User",
            value=f"{avg_distinct_games_per_user:.1f}",
            help="Average number of distinct games completed per hybrid_profile_id"
        )
    
    with col3:
        max_distinct_games = repeatability_df['games_played'].max()
        st.metric(
            label="ðŸ† Max Distinct Games",
            value=f"{max_distinct_games}",
            help="Maximum number of distinct games completed by a single hybrid_profile_id"
        )

def recalculate_time_series_for_games(df_main: pd.DataFrame, time_period: str) -> pd.DataFrame:
    """Recalculate time series data for selected games"""
    if df_main.empty:
        return pd.DataFrame()
    
    # Convert date to datetime (use the correct date column)
    df_main['datetime'] = pd.to_datetime(df_main['date'])
    
    # Filter to July 2nd, 2025 onwards
    july_2_2025 = pd.to_datetime('2025-07-02')
    df_main = df_main[df_main['datetime'] >= july_2_2025]
    
    time_series_data = []
    
    if time_period == "Day":
        # Day-level data (last 2 weeks from available data)
        cutoff_date = df_main['datetime'].max() - pd.Timedelta(days=14)
        df_filtered = df_main[df_main['datetime'] >= cutoff_date].copy()
        df_filtered['time_group'] = df_filtered['datetime'].dt.date
        
        for time_group in df_filtered['time_group'].unique():
            group_data = df_filtered[df_filtered['time_group'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': str(time_group),
                'period_type': 'Day',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "Week":
        # Week-level data (all available data grouped by weeks)
        # Use the earliest date in the data as the reference point
        start_date = df_main['datetime'].min()
        df_filtered = df_main.copy()
        df_filtered['days_since_start'] = (df_filtered['datetime'] - start_date).dt.days
        df_filtered['week_number'] = (df_filtered['days_since_start'] // 7) + 1
        df_filtered['time_group_week'] = 'Week ' + df_filtered['week_number'].astype(str)
        
        for time_group in df_filtered['time_group_week'].unique():
            group_data = df_filtered[df_filtered['time_group_week'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'Week',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "Month":
        # Month-level data (all available data grouped by months)
        df_filtered = df_main.copy()
        df_filtered['time_group_month'] = df_filtered['datetime'].dt.strftime('%B %Y')
        
        for time_group in df_filtered['time_group_month'].unique():
            group_data = df_filtered[df_filtered['time_group_month'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'Month',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    elif time_period == "All time":
        # All time data (all available data grouped by months)
        # Use the same logic as Month but with different period_type
        df_filtered = df_main.copy()
        df_filtered['time_group_month'] = df_filtered['datetime'].dt.strftime('%B %Y')
        
        for time_group in df_filtered['time_group_month'].unique():
            group_data = df_filtered[df_filtered['time_group_month'] == time_group]
            
            started_users = group_data[group_data['event'] == 'Started']['idvisitor_converted'].nunique()
            completed_users = group_data[group_data['event'] == 'Completed']['idvisitor_converted'].nunique()
            started_visits = group_data[group_data['event'] == 'Started']['idvisit'].nunique()
            completed_visits = group_data[group_data['event'] == 'Completed']['idvisit'].nunique()
            started_instances = len(group_data[group_data['event'] == 'Started'])
            completed_instances = len(group_data[group_data['event'] == 'Completed'])
            
            time_series_data.append({
                'time_period': time_group,
                'period_type': 'All time',
                'started_users': started_users,
                'completed_users': completed_users,
                'started_visits': started_visits,
                'completed_visits': completed_visits,
                'started_instances': started_instances,
                'completed_instances': completed_instances
            })
    
    return pd.DataFrame(time_series_data)

def render_time_series_analysis(time_series_df: pd.DataFrame, df_main: pd.DataFrame) -> None:
    """Render time series analysis"""
    import altair as alt
    
    if time_series_df.empty:
        st.warning("No time series data available.")
        return
    
    st.markdown("### ðŸ“ˆ Time-Series Analysis")
    
    # Create columns for filters
    ts_filter_col1, ts_filter_col2, ts_filter_col3 = st.columns(3)
    
    with ts_filter_col1:
        # Time period filter
        time_period = st.selectbox(
            "Select Time Period:",
            options=["Month", "Week", "Day"],
            help="Choose the time aggregation for the time-series graphs"
        )
    
    with ts_filter_col2:
        # Game filter for time series
        unique_games_ts = sorted(df_main['game_name'].unique())
        selected_games_ts = st.multiselect(
            "Select Games:",
            options=unique_games_ts,
            default=[],  # Empty by default - shows all games
            help="Select games to include in time series analysis. Leave empty to show all games."
        )
    
    # ts_filter_col3 reserved for future use
    
    # Use only preprocessed data (like all other graphs)
    if time_series_df.empty:
        st.warning("No time series data available.")
        return
    
    # Filter by selected time period
    filtered_ts_df = time_series_df[time_series_df['period_type'] == time_period].copy()
    
    # Apply July filter for Month view
    if time_period == "Month":
        july_onwards = ['July 2025', 'August 2025', 'September 2025', 'October 2025']
        filtered_ts_df = filtered_ts_df[filtered_ts_df['time_period'].isin(july_onwards)]
    
    # Apply game filtering if specific games are selected
    if selected_games_ts:
        # Filter by selected games
        filtered_ts_df = filtered_ts_df[filtered_ts_df['game_name'].isin(selected_games_ts)]
    
    # Aggregate data by time period to prevent overlapping points
    # Group by time_period and sum the metrics
    aggregated_df = filtered_ts_df.groupby('time_period').agg({
        'started_users': 'sum',
        'completed_users': 'sum',
        'started_visits': 'sum',
        'completed_visits': 'sum',
        'started_instances': 'sum',
        'completed_instances': 'sum'
    }).reset_index()
    
    
    if filtered_ts_df.empty:
        st.warning("No data available for the selected time period.")
        return
    
    # Sort the aggregated dataframe based on time period
    if time_period == "Month":
        # Convert month names to datetime for proper sorting
        try:
            aggregated_df['sort_date'] = pd.to_datetime(aggregated_df['time_period'])
            aggregated_df = aggregated_df.sort_values('sort_date').drop('sort_date', axis=1)
            # Create ordered list for Altair
            time_order = aggregated_df['time_period'].tolist()
        except Exception as e:
            # If datetime parsing fails, use original order
            st.warning(f"Could not parse dates for sorting: {e}")
            time_order = aggregated_df['time_period'].tolist()
    elif time_period == "Week":
        # Extract week number for sorting
        aggregated_df['week_num'] = aggregated_df['time_period'].str.extract(r'(\d+)').astype(int)
        aggregated_df = aggregated_df.sort_values('week_num').drop('week_num', axis=1)
        # Create ordered list for Altair
        time_order = aggregated_df['time_period'].tolist()
    elif time_period == "Day":
        # Sort by date
        try:
            aggregated_df['sort_date'] = pd.to_datetime(aggregated_df['time_period'])
            aggregated_df = aggregated_df.sort_values('sort_date').drop('sort_date', axis=1)
            # Create ordered list for Altair
            time_order = aggregated_df['time_period'].astype(str).tolist()
        except Exception as e:
            # If datetime parsing fails, use original order
            st.warning(f"Could not parse dates for sorting: {e}")
            time_order = aggregated_df['time_period'].astype(str).tolist()
    else:
        time_order = None
    
    # Create separate sections for each metric with tabs for different time periods
    def create_metric_chart(data, metric_name, metric_key, color_scheme):
        """Create chart for a specific metric"""
        chart_data = []
        for _, row in data.iterrows():
            chart_data.extend([
                {'Time': str(row['time_period']), 'Event': 'Started', 'Count': row[f'started_{metric_key}']},
                {'Time': str(row['time_period']), 'Event': 'Completed', 'Count': row[f'completed_{metric_key}']}
            ])
        chart_df = pd.DataFrame(chart_data)
        
        # Line chart for time periods
        lines = alt.Chart(chart_df).mark_line(
            strokeWidth=3,
            point=alt.OverlayMarkDef(
                filled=True,
                size=60,
                stroke='white',
                strokeWidth=1.5
            )
        ).encode(
            x=alt.X('Time:N', title='Time Period', 
                   sort=time_order if time_order else None,
                   axis=alt.Axis(
                       labelAngle=0,
                       labelFontSize=12,
                       labelLimit=150,
                       titleFontSize=14
                   )),
            y=alt.Y('Count:Q', title=f'Number of {metric_name}', axis=alt.Axis(format='~s')),
            color=alt.Color('Event:N', 
                          scale=alt.Scale(domain=['Started', 'Completed'], 
                                        range=color_scheme),
                          legend=alt.Legend(title="Event Type")),
            tooltip=['Time:N', 'Event:N', 'Count:Q']
        ).properties(
            width=900,
            height=400,
            title=f'{metric_name}: Started vs Completed'
        )
        
        # Add data labels only for every other point to reduce clutter
        started_data = chart_df[chart_df['Event'] == 'Started']
        completed_data = chart_df[chart_df['Event'] == 'Completed']
        
        # Show labels only for every other point to reduce clutter
        started_labels = alt.Chart(started_data[::2]).mark_text(
            align='center',
            baseline='bottom',
            color=color_scheme[0],
            fontSize=11,
            fontWeight='bold',
            dy=-12
        ).encode(
            x=alt.X('Time:N', sort=time_order if time_order else None),
            y=alt.Y('Count:Q'),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        completed_labels = alt.Chart(completed_data[::2]).mark_text(
            align='center',
            baseline='top',
            color=color_scheme[1],
            fontSize=11,
            fontWeight='bold',
            dy=12
        ).encode(
            x=alt.X('Time:N', sort=time_order if time_order else None),
            y=alt.Y('Count:Q'),
            text=alt.Text('Count:Q', format='.0f')
        )
        
        return (lines + started_labels + completed_labels).configure_axis(
            labelFontSize=18,
            titleFontSize=20,
            grid=True
        ).configure_title(
            fontSize=24,
            fontWeight='bold'
        )
    
    # Users Section
    st.markdown("### ðŸ‘¥ Users Analysis")
    users_chart = create_metric_chart(aggregated_df, "Users", "users", ['#FF6B6B', '#4ECDC4'])
    st.altair_chart(users_chart, use_container_width=True)
    
    # Visits Section
    st.markdown("### ðŸ”„ Visits Analysis")
    visits_chart = create_metric_chart(aggregated_df, "Visits", "visits", ['#FF6B6B', '#4ECDC4'])
    st.altair_chart(visits_chart, use_container_width=True)
    
    # Instances Section
    st.markdown("### âš¡ Instances Analysis")
    instances_chart = create_metric_chart(aggregated_df, "Instances", "instances", ['#FF6B6B', '#4ECDC4'])
    st.altair_chart(instances_chart, use_container_width=True)

def main() -> None:
    st.set_page_config(page_title="Hybrid Dashboard", layout="wide")
    st.title("Hybrid Dashboard")
    st.caption("Performance Optimized - Using Preprocessed Data v2.1")
    
    
    # Check if processed data exists
    check_processed_data()
    
    with st.spinner("Loading data..."):
        (df_main, summary_df, time_series_df, 
         repeatability_df, score_distribution_df, metadata) = load_processed_data()
    
    if df_main.empty:
        st.warning("No data available.")
        return
    
    # Add filters
    st.markdown("### ðŸŽ® Filters")
    
    # Create two columns for filters
    filter_col1, filter_col2 = st.columns(2)
    
    with filter_col1:
        # Game Name filter - get unique games from df_main
        unique_games = sorted(df_main['game_name'].unique()) if 'game_name' in df_main.columns else ['Sample Game']
        selected_games = st.multiselect(
            "Select Game Names to filter by:",
            options=unique_games,
            default=[],  # Empty by default - shows all games
            help="Select one or more games to filter the dashboard data. Leave empty to show all games."
        )
    
    with filter_col2:
        # Date filter - use time series data for date range
        if not time_series_df.empty:
            # Extract dates from time_period column
            time_series_df['date'] = pd.to_datetime(time_series_df['time_period'], errors='coerce')
            min_date = time_series_df['date'].min().date()
            max_date = time_series_df['date'].max().date()
        else:
            min_date = pd.to_datetime('2025-07-02').date()
            max_date = pd.to_datetime('2025-10-24').date()
        
        # Create date range picker
        date_range = st.date_input(
            "Select Date Range:",
            value=(min_date, max_date),
            min_value=min_date,
            max_value=max_date,
            help="Select a date range to filter the data. Data is available from July 2nd, 2025 onwards."
        )
    
    # Show filter summary
    if len(date_range) == 2:
        date_summary = f"from {date_range[0]} to {date_range[1]}"
    elif len(date_range) == 1:
        date_summary = f"on {date_range[0]}"
    else:
        date_summary = "for all dates"
    
    # Show filter summary
    if not selected_games or len(selected_games) == len(unique_games):
        game_summary = "**All Games**"
        game_count = len(unique_games)
    else:
        game_summary = f"{', '.join(selected_games)}"
        game_count = len(selected_games)
    
    # Render conversion funnel based on game selection
    if not selected_games or len(selected_games) == len(unique_games):
        # Show total conversion funnel
        render_modern_dashboard(summary_df, summary_df)
    else:
        # Show filtered conversion funnel
        df_filtered = df_main[df_main['game_name'].isin(selected_games)]
        render_modern_dashboard(df_filtered, df_filtered)
    
    # Add Score Distribution Analysis
    st.markdown("---")
    st.markdown("## ðŸŽ¯ Score Distribution Analysis")
    
    if not score_distribution_df.empty:
        render_score_distribution_chart(score_distribution_df)
    else:
        st.warning("No score distribution data available.")
    
    # Add Repeatability Analysis
    st.markdown("---")
    st.markdown("## ðŸŽ® Game Repeatability Analysis")
    
    if not repeatability_df.empty:
        render_repeatability_analysis(repeatability_df)
    else:
        st.warning("No repeatability data available.")
    
    # Add Time Series Analysis
    st.markdown("---")
    st.markdown("## ðŸ“ˆ Time-Series Analysis")
    
    if not time_series_df.empty:
        render_time_series_analysis(time_series_df, df_main)
    else:
        st.warning("No time series data available.")


if __name__ == "__main__":
    main()